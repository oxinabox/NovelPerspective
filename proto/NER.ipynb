{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sample_chapters import *\n",
    "from feature_extraction import *\n",
    "from classify import *\n",
    "from book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_characters(annotated_data):\n",
    "    full_characters = np.asarray([datum['character'] for datum in annotated_data])\n",
    "    full_texts = np.asarray([datum['text'] for datum in annotated_data])\n",
    "    return full_texts, full_characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def xval_evaluate(annotated_data, solver, n_splits=10, metric=accuracy_score, mute=True):\n",
    "    \n",
    "    full_texts, full_characters = extract_texts_and_characters(annotated_data)\n",
    "    \n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):        \n",
    "        train_ann_data = annotated_data[train_inds]\n",
    "        test_ann_data = annotated_data[test_inds]\n",
    "\n",
    "        score = train_test_evaluate(train_ann_data, test_ann_data, solver, n_splits, metric)\n",
    "        \n",
    "        if not(mute):\n",
    "            print(score)\n",
    "            \n",
    "        scores.append(score)\n",
    "    return np.mean(scores, axis=0)\n",
    "\n",
    "\n",
    "def evaluate(train_ann_data, test_ann_data, solver, n_splits=10, metric=accuracy_score):   \n",
    "    train_texts, train_characters = extract_texts_and_characters(train_ann_data)\n",
    "    test_texts, test_characters = extract_texts_and_characters(test_ann_data)\n",
    "\n",
    "    solver.train(train_texts, train_characters)\n",
    "    score = solver.test(test_texts, test_characters, metric=metric)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:  348 92 256\n",
      "POVs:  22 7 15\n"
     ]
    }
   ],
   "source": [
    "nicknames2name_comb = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "    \"Rollins\" : \"Pekka\"\n",
    "}\n",
    "\n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_ASOIAF = np.asarray(json.load(fh))\n",
    "    \n",
    "    \n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.asarray(json.load(fh))\n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.hstack([ann_SOC, np.asarray(json.load(fh))])\n",
    "\n",
    "ann_comb = np.hstack([ann_SOC, ann_ASOIAF])\n",
    "\n",
    "np.random.shuffle(ann_ASOIAF)\n",
    "np.random.shuffle(ann_SOC)\n",
    "np.random.shuffle(ann_comb)\n",
    "print(\"lengths: \", len(ann_comb), len(ann_SOC), len(ann_ASOIAF))\n",
    "print(\"POVs: \", *[len(np.unique(extract_texts_and_characters(ann)[1])) for ann in (ann_comb, ann_SOC, ann_ASOIAF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3],[1,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def all_metrics(tt,pp):\n",
    "    prf = precision_recall_fscore_support(tt,pp, average='macro', labels=np.unique(tt))[0:3]\n",
    "    acc = accuracy_score(tt,pp)\n",
    "    return np.hstack([prf, acc])\n",
    "\n",
    "all_metrics_names = [\"P\", \"R\", \"F1\", \"Acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASOIAF', 'First Mentioned')  [0.02190518 0.07219788 0.03227254 0.25      ]\n",
      "('ASOIAF', 'ML Classical Features Trained on SOC')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.46787058 0.48834536 0.47662706 0.91796875]\n",
      "('ASOIAF', 'Most Commonly Mentioned')  [0.55891593 0.58322807 0.56732114 0.91015625]\n",
      "('SOC', 'First Mentioned')  [0.1010101  0.19498747 0.13106484 0.36956522]\n",
      "('SOC', 'ML Classical Features Trained on ASOIAF')  [0.72222222 0.74691358 0.73384168 0.91304348]\n",
      "('SOC', 'Most Commonly Mentioned')  [0.53948577 0.57805326 0.55175282 0.7826087 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, First Mentioned)</th>\n",
       "      <td>0.0219052</td>\n",
       "      <td>0.0721979</td>\n",
       "      <td>0.0322725</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, ML Classical Features Trained on SOC)</th>\n",
       "      <td>0.467871</td>\n",
       "      <td>0.488345</td>\n",
       "      <td>0.476627</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, Most Commonly Mentioned)</th>\n",
       "      <td>0.558916</td>\n",
       "      <td>0.583228</td>\n",
       "      <td>0.567321</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, First Mentioned)</th>\n",
       "      <td>0.10101</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>0.131065</td>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, ML Classical Features Trained on ASOIAF)</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.746914</td>\n",
       "      <td>0.733842</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, Most Commonly Mentioned)</th>\n",
       "      <td>0.539486</td>\n",
       "      <td>0.578053</td>\n",
       "      <td>0.551753</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        P          R  \\\n",
       "(ASOIAF, First Mentioned)                       0.0219052  0.0721979   \n",
       "(ASOIAF, ML Classical Features Trained on SOC)   0.467871   0.488345   \n",
       "(ASOIAF, Most Commonly Mentioned)                0.558916   0.583228   \n",
       "(SOC, First Mentioned)                            0.10101   0.194987   \n",
       "(SOC, ML Classical Features Trained on ASOIAF)   0.722222   0.746914   \n",
       "(SOC, Most Commonly Mentioned)                   0.539486   0.578053   \n",
       "\n",
       "                                                       F1       Acc  \n",
       "(ASOIAF, First Mentioned)                       0.0322725      0.25  \n",
       "(ASOIAF, ML Classical Features Trained on SOC)   0.476627  0.917969  \n",
       "(ASOIAF, Most Commonly Mentioned)                0.567321  0.910156  \n",
       "(SOC, First Mentioned)                           0.131065  0.369565  \n",
       "(SOC, ML Classical Features Trained on ASOIAF)   0.733842  0.913043  \n",
       "(SOC, Most Commonly Mentioned)                   0.551753  0.782609  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_mdl = MLCharacterSolver(XGBClassifier(), nicknames2name_comb)\n",
    "FM_mdl = FirstMentionedSolver(nicknames2name_comb)\n",
    "MC_mdl = MostMentionedSolver(nicknames2name_comb)\n",
    "\n",
    "\n",
    "program = {\n",
    "    (\"ASOIAF\", \"ML Classical Features Trained on SOC\"): (ann_SOC, ann_ASOIAF, ML_mdl) ,\n",
    "    (\"SOC\", \"ML Classical Features Trained on ASOIAF\"): (ann_ASOIAF, ann_SOC, ML_mdl),   \n",
    "    (\"SOC\", \"First Mentioned\") :                        ([], ann_SOC, FM_mdl),\n",
    "    (\"ASOIAF\", \"First Mentioned\"):                      ([], ann_ASOIAF, FM_mdl),\n",
    "    (\"SOC\", \"Most Commonly Mentioned\"):                 ([], ann_SOC, MC_mdl),\n",
    "    (\"ASOIAF\", \"Most Commonly Mentioned\"):              ([], ann_ASOIAF, MC_mdl),\n",
    "}\n",
    "\n",
    "\n",
    "res = pd.DataFrame(index=program.keys(), columns = all_metrics_names)\n",
    "res.sort_index(inplace=True)\n",
    "\n",
    "for ind in res.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = evaluate(*program[ind], metric=all_metrics)\n",
    "    res.loc[ind,:] = score\n",
    "    print(\" \", score)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Evaluation\n",
    "To test how much it effects things from different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASOIAF', 'First Mentioned')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.11669051 0.20019236 0.13732956 0.25015385]\n",
      "('ASOIAF', 'ML Classical Features')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.92700105 0.94379371 0.93134033 0.96076923]\n",
      "('ASOIAF', 'Most Commonly Mentioned')  [0.81248182 0.84622183 0.82171873 0.91      ]\n",
      "('SOC', 'First Mentioned')  [0.27833333 0.33738095 0.28857143 0.37      ]\n",
      "('SOC', 'ML Classical Features')  [1.         0.97777778 0.98333333 0.97777778]\n",
      "('SOC', 'Most Commonly Mentioned')  [0.75125    0.75875    0.73228571 0.78444444]\n",
      "('combined', 'First Mentioned')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.12824748 0.21695928 0.15304311 0.28168067]\n",
      "('combined', 'ML Classical Features')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.90938834 0.92889816 0.91559743 0.95983193]\n",
      "('combined', 'Most Commonly Mentioned')  [0.7859963  0.80562511 0.78858755 0.87647059]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, First Mentioned)</th>\n",
       "      <td>0.116691</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.13733</td>\n",
       "      <td>0.250154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, ML Classical Features)</th>\n",
       "      <td>0.927001</td>\n",
       "      <td>0.943794</td>\n",
       "      <td>0.93134</td>\n",
       "      <td>0.960769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, Most Commonly Mentioned)</th>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.846222</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, First Mentioned)</th>\n",
       "      <td>0.278333</td>\n",
       "      <td>0.337381</td>\n",
       "      <td>0.288571</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, ML Classical Features)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, Most Commonly Mentioned)</th>\n",
       "      <td>0.75125</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>0.732286</td>\n",
       "      <td>0.784444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, First Mentioned)</th>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.216959</td>\n",
       "      <td>0.153043</td>\n",
       "      <td>0.281681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, ML Classical Features)</th>\n",
       "      <td>0.909388</td>\n",
       "      <td>0.928898</td>\n",
       "      <td>0.915597</td>\n",
       "      <td>0.959832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, Most Commonly Mentioned)</th>\n",
       "      <td>0.785996</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.788588</td>\n",
       "      <td>0.876471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            P         R        F1       Acc\n",
       "(ASOIAF, First Mentioned)            0.116691  0.200192   0.13733  0.250154\n",
       "(ASOIAF, ML Classical Features)      0.927001  0.943794   0.93134  0.960769\n",
       "(ASOIAF, Most Commonly Mentioned)    0.812482  0.846222  0.821719      0.91\n",
       "(SOC, First Mentioned)               0.278333  0.337381  0.288571      0.37\n",
       "(SOC, ML Classical Features)                1  0.977778  0.983333  0.977778\n",
       "(SOC, Most Commonly Mentioned)        0.75125   0.75875  0.732286  0.784444\n",
       "(combined, First Mentioned)          0.128247  0.216959  0.153043  0.281681\n",
       "(combined, ML Classical Features)    0.909388  0.928898  0.915597  0.959832\n",
       "(combined, Most Commonly Mentioned)  0.785996  0.805625  0.788588  0.876471"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program = {\n",
    "    (\"ASOIAF\", \"ML Classical Features\"):                (ann_ASOIAF, ML_mdl),\n",
    "    (\"SOC\", \"ML Classical Features\"):                   (ann_SOC, ML_mdl),\n",
    "    (\"combined\", \"ML Classical Features\"):              (ann_comb, ML_mdl),\n",
    "    \n",
    "    (\"SOC\", \"First Mentioned\"):                         (ann_SOC, FM_mdl),\n",
    "    (\"ASOIAF\", \"First Mentioned\"):                      (ann_ASOIAF, FM_mdl),\n",
    "    (\"combined\", \"First Mentioned\"):                    (ann_comb, FM_mdl),\n",
    "    \n",
    "    (\"SOC\", \"Most Commonly Mentioned\"):                 (ann_SOC, MC_mdl),\n",
    "    (\"ASOIAF\", \"Most Commonly Mentioned\"):              (ann_ASOIAF, MC_mdl),\n",
    "    (\"combined\", \"Most Commonly Mentioned\"):            (ann_comb, MC_mdl),\n",
    "}\n",
    "\n",
    "res_xval = pd.DataFrame(index=program.keys(), columns = all_metrics_names)\n",
    "res_xval.sort_index(inplace=True)\n",
    "\n",
    "for ind in res_xval.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = xval_evaluate(*program[ind], metric=all_metrics) \n",
    "    res_xval.loc[ind, :] = score\n",
    "    print(\" \", score)\n",
    "    \n",
    "res_xval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(ann, filename):\n",
    "    mdl = MLCharacterSolver(XGBClassifier())\n",
    "    mdl.train(*extract_texts_and_characters(ann))\n",
    "    joblib.dump(mdl, \"../trained_models/\"+filename+\".pkl\")\n",
    "    return mdl\n",
    "\n",
    "train_and_save_model(ann_ASOIAF, \"classic_ASOIAF\")\n",
    "train_and_save_model(ann_SOC, \"classic_SOC\")\n",
    "\n",
    "mdl_comb = train_and_save_model(ann_comb, \"classic_comb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.07692308, 'occur_percent'),\n",
       " (0.07371795, 'last_occur_percent'),\n",
       " (0.057692308, 'rank'),\n",
       " (0.057692308, 'after_POS_was_VBD'),\n",
       " (0.051282052, 'rank_percent'),\n",
       " (0.049679488, 'before_POS_was_percent_.'),\n",
       " (0.043269232, 'last_occur_position'),\n",
       " (0.03846154, 'before_POS_was_percent_NN'),\n",
       " (0.033653848, 'before_POS_was_,')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_comb[1]['text'])\n",
    "feature_weights = list(zip(mdl_comb.classifier.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([weight for weight, _ in feature_weights if weight>0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
