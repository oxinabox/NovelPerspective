{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sample_chapters import *\n",
    "from feature_extraction import *\n",
    "from classify import *\n",
    "from book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_texts_and_characters(annotated_data):\n",
    "    full_characters = np.asarray([datum['character'] for datum in annotated_data])\n",
    "    full_texts = np.asarray([datum['text'] for datum in annotated_data])\n",
    "    return full_texts, full_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def xval_evaluate(annotated_data, solver, n_splits=10, metric=accuracy_score, mute=True):\n",
    "    \n",
    "    full_texts, full_characters = extract_texts_and_characters(annotated_data)\n",
    "    \n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):        \n",
    "        train_ann_data = annotated_data[train_inds]\n",
    "        test_ann_data = annotated_data[test_inds]\n",
    "\n",
    "        score = evaluate(train_ann_data, test_ann_data, solver, metric)\n",
    "        if not(mute):\n",
    "            print(score)\n",
    "            \n",
    "        scores.append(score)\n",
    "    return np.mean(scores, axis=0)\n",
    "\n",
    "\n",
    "def evaluate(train_ann_data, test_ann_data, solver, metric=accuracy_score):   \n",
    "    train_texts, train_characters = extract_texts_and_characters(train_ann_data)\n",
    "    test_texts, test_characters = extract_texts_and_characters(test_ann_data)\n",
    "\n",
    "    solver.train(train_texts, train_characters)\n",
    "    score = solver.test(test_texts, test_characters, metric=metric)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:  348 92 256\n",
      "POVs:  22 7 15\n"
     ]
    }
   ],
   "source": [
    "nicknames2name_comb = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "    \"Rollins\" : \"Pekka\"\n",
    "}\n",
    "\n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_ASOIAF = np.asarray(json.load(fh))\n",
    "    \n",
    "    \n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.asarray(json.load(fh))\n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.hstack([ann_SOC, np.asarray(json.load(fh))])\n",
    "\n",
    "ann_comb = np.hstack([ann_SOC, ann_ASOIAF])\n",
    "\n",
    "np.random.shuffle(ann_ASOIAF)\n",
    "np.random.shuffle(ann_SOC)\n",
    "np.random.shuffle(ann_comb)\n",
    "print(\"lengths: \", len(ann_comb), len(ann_SOC), len(ann_ASOIAF))\n",
    "print(\"POVs: \", *[len(np.unique(extract_texts_and_characters(ann)[1])) for ann in (ann_comb, ann_SOC, ann_ASOIAF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def hybrid_features(x):\n",
    "    emb_names, emb_vecs, _ = get_embedding_features(x, 5)\n",
    "    cl_names, cl_vecs, _ = get_feature_vectors(x)\n",
    "    #print(cl_names)\n",
    "    #print(\"*********\")\n",
    "    #print(emb_names)\n",
    "    assert cl_names == emb_names\n",
    "    vecs = np.hstack([cl_vecs, emb_vecs])\n",
    "    assert vecs.shape[0]==len(cl_names)\n",
    "    assert vecs.shape[1]>2\n",
    "    return cl_names, vecs, \"hybrid\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def all_metrics(tt,pp):\n",
    "    prf = precision_recall_fscore_support(tt,pp, average='micro', labels=np.unique(tt))[0:3]\n",
    "    acc = accuracy_score(tt,pp)\n",
    "    return np.hstack([prf, acc])\n",
    "\n",
    "all_metrics_names = [\"P\", \"R\", \"F1\", \"Acc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def relabel_grp_preds(y_true, y_pred):\n",
    "    if  y_true.sum()<1:\n",
    "        return #No positive samples, thus no rescaling required\n",
    "    \n",
    "    assert (y_true==0).sum()==len(y_true)-1\n",
    "\n",
    "    target_inds = y_true>0.5 # Actually it is always 0 or 1, but force it to logical\n",
    "    other_inds = np.logical_not(target_inds)\n",
    "\n",
    "    target_score = y_pred[target_inds]\n",
    "    target_penalty = 0 #y_pred[other_inds].max()\n",
    "    other_penalty = 0#target_score/(len(y_true)-1)\n",
    "\n",
    "    # Fake out the scores\n",
    "    y_pred[target_inds] -= target_penalty # increase it's loss\n",
    "    y_pred[other_inds]  += other_penalty #Decreases their loss\n",
    "\n",
    "class GroupedMLCharacterSolver(MLCharacterSolver):\n",
    "\n",
    "\n",
    "    def var_logregobj(y_true, y_pred):\n",
    "\n",
    "        #oy_pred=y_pred.copy()\n",
    "        for g_ind in G_inds:\n",
    "            relabel_grp_preds(y_true[g_ind], y_pred[g_ind]) #Inplace\n",
    "\n",
    "        #print(np.vstack([oy_pred, y_pred, y_true]).T)\n",
    "        #print(\"------------\")\n",
    "\n",
    "        y_pred = 1.0 / (1.0 + np.exp(-y_pred))\n",
    "        grad = y_pred-y_true\n",
    "        hess = y_pred * (1.0 - y_true)\n",
    "        return grad, hess\n",
    "\n",
    "    def train(self, texts, reference_characters):\n",
    "        Xs = [] # Feature vectors\n",
    "        Ys = [] # Binary as to if this feature is the target\n",
    "        last_ind = 0\n",
    "        G_inds = []\n",
    "        for reference_name, raw_text in zip(reference_characters, texts):\n",
    "            names, vectors, _ = self.feature_extractor(raw_text)\n",
    "            Xs.extend(vectors)\n",
    "            y = [(name == reference_name) for name in names]\n",
    "            Ys.extend(y)\n",
    "            first_ind = last_ind\n",
    "            last_ind += len(names)\n",
    "            G_inds.append(slice(first_ind,last_ind))\n",
    "\n",
    "        Xs = np.asarray(Xs)\n",
    "        Ys = np.asarray(Ys)\n",
    "        assert Xs.shape[0]==Ys.shape[0], (Xs.shape[0], Ys.shape[0])\n",
    "        assert len(Xs.shape)==2, \"Xs.shape = \"+str(Xs.shape)\n",
    "        assert Xs.shape[1]>2, \"Xs.shape[1] = \"+str(Xs.shape[1])\n",
    "\n",
    "        # closure over G_inds\n",
    "        def var_logregobj(y_true, y_pred):\n",
    "            #for g_ind in G_inds:\n",
    "            #    relabel_grp_preds(y_true[g_ind], y_pred[g_ind]) #Inplace\n",
    "            \n",
    "            y_pred =  1.0 / (1.0 + np.exp(-y_pred))\n",
    "            grad = y_pred-y_true\n",
    "            eps=1e-16;\n",
    "            hess = np.maximum(y_pred * (1.0 - y_pred), eps);\n",
    "            return grad, hess\n",
    "\n",
    "        self.classifier.objective = var_logregobj #Over write it to the closure\n",
    "        self.classifier.fit(Xs,Ys)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ann_SOC_texts, ann_SOC_chars  = extract_texts_and_characters(ann_SOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clmdd = CL_mdl()\n",
    "evaluate(ann_SOC, ann_SOC, clmdd)\n",
    "clmdd.choose_character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.695652173913\n"
     ]
    }
   ],
   "source": [
    "GML_mdl = GroupedMLCharacterSolver(XGBClassifier(), nicknames2name=nicknames2name_comb)\n",
    "print(evaluate(ann_SOC, ann_SOC, GML_mdl))\n",
    "out_chars = list(GML_mdl.choose_characters(ann_SOC_texts) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inds = ann_SOC_chars!=out_chars\n",
    "hard_chars = ann_SOC_chars[inds]\n",
    "hard_texts = ann_SOC_texts[inds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.071906172, 'Nina'),\n",
       " (0.88273704, 'Matthias'),\n",
       " (0.0004262751, 'Brum'),\n",
       " (0.01146984, 'Jarl'),\n",
       " (0.00045013832, 'Elderclock'),\n",
       " (0.00040778279, 'Ferolind'),\n",
       " (0.00032514276, 'Grisha'),\n",
       " (0.00049540796, 'Fjerdan'),\n",
       " (0.0022502665, 'Specht'),\n",
       " (0.00027771172, 'Inej'),\n",
       " (0.00020608658, 'Grisha Fabrikators'),\n",
       " (0.00043655053, 'Claas'),\n",
       " (0.00027771172, 'Corecloth'),\n",
       " (0.00043655053, 'Giert'),\n",
       " (0.00023983637, 'Avfalle'),\n",
       " (0.00022914723, 'Djel'),\n",
       " (0.005693309, 'Wylan'),\n",
       " (0.00027771172, 'Nothing'),\n",
       " (0.00027771172, 'Lars'),\n",
       " (0.00022914723, 'Jesper'),\n",
       " (0.00020608658, 'None')]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*clmdd.character_scores(hard_texts[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.019663431, 'Nina'),\n",
       " (1.5805703e-09, 'Matthias'),\n",
       " (1.5805703e-09, 'Brum'),\n",
       " (1.5805703e-09, 'Jarl'),\n",
       " (1.5805703e-09, 'Elderclock'),\n",
       " (1.5805703e-09, 'Ferolind'),\n",
       " (1.5805703e-09, 'Grisha'),\n",
       " (1.5805703e-09, 'Fjerdan'),\n",
       " (1.5805703e-09, 'Specht'),\n",
       " (1.5805703e-09, 'Inej'),\n",
       " (1.5805703e-09, 'Grisha Fabrikators'),\n",
       " (1.5805703e-09, 'Claas'),\n",
       " (1.5805703e-09, 'Corecloth'),\n",
       " (1.5805703e-09, 'Giert'),\n",
       " (1.5805703e-09, 'Avfalle'),\n",
       " (1.5805703e-09, 'Djel'),\n",
       " (1.5805703e-09, 'Wylan'),\n",
       " (1.5805703e-09, 'Nothing'),\n",
       " (1.5805703e-09, 'Lars'),\n",
       " (1.5805703e-09, 'Jesper'),\n",
       " (1.5805703e-09, 'None')]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(*GML_mdl.character_scores(hard_texts[5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Inej', 'Matthias', 'Inej', 'Kaz', 'Nina', 'Kaz', 'Nina', 'Matthias'], \n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hard_chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84782608695652173"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GML_mdl = GroupedMLCharacterSolver(XGBClassifier(), nicknames2name=nicknames2name_comb)\n",
    "evaluate(ann_ASOIAF, ann_SOC, GML_mdl) #0.86956521739130432"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91304347826086951"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ann_ASOIAF, ann_SOC, CL_mdl())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "WE_mdl = lambda: MLCharacterSolver(XGBClassifier(), nicknames2name_comb, lambda x:get_embedding_features(x,5))\n",
    "CL_mdl = lambda: MLCharacterSolver(XGBClassifier(), nicknames2name_comb)\n",
    "HY_mdl = lambda: MLCharacterSolver(XGBClassifier(), nicknames2name_comb, hybrid_features)\n",
    "\n",
    "\n",
    "FM_mdl = lambda: FirstMentionedSolver(nicknames2name_comb)\n",
    "MC_mdl = lambda: MostMentionedSolver(nicknames2name_comb)\n",
    "\n",
    "datasets = [(\"ASIAF\", ann_ASOIAF), (\"SOC\", ann_SOC)]\n",
    "base_mdls = [(\"ML Classical Features\", CL_mdl),\n",
    "        (\"ML Hybrid Features\", HY_mdl),\n",
    "        (\"ML Word Emb. Features\", WE_mdl),\n",
    "        (\"First Mentioned\", FM_mdl),\n",
    "        (\"Most Commonly Mentioned\", MC_mdl)\n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "WO_mdl = lambda: MLCharacterSolver(XGBClassifier(), nicknames2name_comb, lambda x:get_embedding_features(x,5, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.84782609,  0.84782609,  0.84782609,  0.84782609])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ann_ASOIAF, ann_SOC, WO_mdl(), metric=all_metrics) #0.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.921875,  0.921875,  0.921875,  0.921875])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(ann_SOC, ann_ASOIAF, WO_mdl(), metric=all_metrics) #0.921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASIAF', 'First Mentioned')  [ 0.25101215  0.2421875   0.24652087  0.2421875 ]\n",
      "('ASIAF', 'ML Classical Features trained on SOC')  [ 0.9140625  0.9140625  0.9140625  0.9140625]\n",
      "('ASIAF', 'ML Hybrid Features trained on SOC')  [ 0.9140625  0.9140625  0.9140625  0.9140625]\n",
      "('ASIAF', 'ML Word Emb. Features trained on SOC')  [ 0.89453125  0.89453125  0.89453125  0.89453125]\n",
      "('ASIAF', 'Most Commonly Mentioned')  [ 0.92578125  0.92578125  0.92578125  0.92578125]\n",
      "('SOC', 'First Mentioned')  [ 0.34090909  0.32608696  0.33333333  0.32608696]\n",
      "('SOC', 'ML Classical Features trained on ASIAF')  [ 0.91304348  0.91304348  0.91304348  0.91304348]\n",
      "('SOC', 'ML Hybrid Features trained on ASIAF')  [ 0.91304348  0.91304348  0.91304348  0.91304348]\n",
      "('SOC', 'ML Word Emb. Features trained on ASIAF')  [ 0.69565217  0.69565217  0.69565217  0.69565217]\n",
      "('SOC', 'Most Commonly Mentioned')  [ 0.84782609  0.84782609  0.84782609  0.84782609]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ASIAF</th>\n",
       "      <th>First Mentioned</th>\n",
       "      <td>0.2510121</td>\n",
       "      <td>0.2421875</td>\n",
       "      <td>0.2465209</td>\n",
       "      <td>0.2421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML Classical Features trained on SOC</th>\n",
       "      <td>0.9140625</td>\n",
       "      <td>0.9140625</td>\n",
       "      <td>0.9140625</td>\n",
       "      <td>0.9140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML Hybrid Features trained on SOC</th>\n",
       "      <td>0.9140625</td>\n",
       "      <td>0.9140625</td>\n",
       "      <td>0.9140625</td>\n",
       "      <td>0.9140625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML Word Emb. Features trained on SOC</th>\n",
       "      <td>0.8945312</td>\n",
       "      <td>0.8945312</td>\n",
       "      <td>0.8945312</td>\n",
       "      <td>0.8945312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most Commonly Mentioned</th>\n",
       "      <td>0.9257812</td>\n",
       "      <td>0.9257812</td>\n",
       "      <td>0.9257812</td>\n",
       "      <td>0.9257812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">SOC</th>\n",
       "      <th>First Mentioned</th>\n",
       "      <td>0.3409091</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.3333333</td>\n",
       "      <td>0.326087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML Classical Features trained on ASIAF</th>\n",
       "      <td>0.9130435</td>\n",
       "      <td>0.9130435</td>\n",
       "      <td>0.9130435</td>\n",
       "      <td>0.9130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML Hybrid Features trained on ASIAF</th>\n",
       "      <td>0.9130435</td>\n",
       "      <td>0.9130435</td>\n",
       "      <td>0.9130435</td>\n",
       "      <td>0.9130435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ML Word Emb. Features trained on ASIAF</th>\n",
       "      <td>0.6956522</td>\n",
       "      <td>0.6956522</td>\n",
       "      <td>0.6956522</td>\n",
       "      <td>0.6956522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Most Commonly Mentioned</th>\n",
       "      <td>0.8478261</td>\n",
       "      <td>0.8478261</td>\n",
       "      <td>0.8478261</td>\n",
       "      <td>0.8478261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      P          R         F1  \\\n",
       "ASIAF First Mentioned                         0.2510121  0.2421875  0.2465209   \n",
       "      ML Classical Features trained on SOC    0.9140625  0.9140625  0.9140625   \n",
       "      ML Hybrid Features trained on SOC       0.9140625  0.9140625  0.9140625   \n",
       "      ML Word Emb. Features trained on SOC    0.8945312  0.8945312  0.8945312   \n",
       "      Most Commonly Mentioned                 0.9257812  0.9257812  0.9257812   \n",
       "SOC   First Mentioned                         0.3409091   0.326087  0.3333333   \n",
       "      ML Classical Features trained on ASIAF  0.9130435  0.9130435  0.9130435   \n",
       "      ML Hybrid Features trained on ASIAF     0.9130435  0.9130435  0.9130435   \n",
       "      ML Word Emb. Features trained on ASIAF  0.6956522  0.6956522  0.6956522   \n",
       "      Most Commonly Mentioned                 0.8478261  0.8478261  0.8478261   \n",
       "\n",
       "                                                    Acc  \n",
       "ASIAF First Mentioned                         0.2421875  \n",
       "      ML Classical Features trained on SOC    0.9140625  \n",
       "      ML Hybrid Features trained on SOC       0.9140625  \n",
       "      ML Word Emb. Features trained on SOC    0.8945312  \n",
       "      Most Commonly Mentioned                 0.9257812  \n",
       "SOC   First Mentioned                          0.326087  \n",
       "      ML Classical Features trained on ASIAF  0.9130435  \n",
       "      ML Hybrid Features trained on ASIAF     0.9130435  \n",
       "      ML Word Emb. Features trained on ASIAF  0.6956522  \n",
       "      Most Commonly Mentioned                 0.8478261  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def make_program(datasets, mdls):\n",
    "    program = dict()    \n",
    "    for (test_data_name, test_data),(mdl_name,mdl) in it.product(datasets, mdls):\n",
    "        if mdl_name[0:2]==\"ML\":\n",
    "            for (train_data_name, train_data) in datasets:\n",
    "                if train_data_name==test_data_name:\n",
    "                    continue\n",
    "                \n",
    "                program[(test_data_name, mdl_name+\" trained on \" + train_data_name)] = (\n",
    "                    train_data,\n",
    "                    test_data,\n",
    "                    mdl()\n",
    "                )\n",
    "        else:\n",
    "            program[(test_data_name, mdl_name)] = ([], test_data, mdl())\n",
    "    return program\n",
    "\n",
    "program = make_program(datasets, base_mdls)\n",
    "\n",
    "\n",
    "res = pd.DataFrame(index=pd.MultiIndex.from_tuples(program.keys()),\n",
    "                   columns = all_metrics_names)\n",
    "res.sort_index(inplace=True)\n",
    "\n",
    "for ind in res.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = \n",
    "    res.loc[ind,:] = score\n",
    "    print(\" \", score)\n",
    "\n",
    "    \n",
    "res.to_csv(\"../results/maineval.csv\", index_label=[\"Testset\", \"Method\"])\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Evaluation\n",
    "To test how much it effects things from different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASIAF', 'First Mentioned') "
     ]
    }
   ],
   "source": [
    "def make_program(datasets, mdls):\n",
    "    program = dict()    \n",
    "    for (data_name, data),(mdl_name,mdl) in it.product(datasets, mdls):\n",
    "        program[(data_name, mdl_name)] = (data, mdl())\n",
    "    return program\n",
    "program = make_program(datasets+[(\"Combined\", ann_comb)], base_mdls)\n",
    "\n",
    "\n",
    "res_xval = pd.DataFrame(index=pd.MultiIndex.from_tuples(program.keys()),\n",
    "                        columns = all_metrics_names)\n",
    "res_xval.sort_index(inplace=True)\n",
    "\n",
    "for ind in res_xval.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = xval_evaluate(*program[ind], metric=all_metrics) \n",
    "    res_xval.loc[ind, :] = score\n",
    "    print(\" \", score)\n",
    "\n",
    "res_xval.to_csv(\"../results/crosseval.csv\", index_label=[\"Dataset\", \"Method\"])\n",
    "    \n",
    "res_xval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_save_model(ann, filename):\n",
    "    mdl = MLCharacterSolver(XGBClassifier())\n",
    "    mdl.train(*extract_texts_and_characters(ann))\n",
    "    joblib.dump(mdl, \"../trained_models/\"+filename+\".pkl\")\n",
    "    return mdl\n",
    "\n",
    "train_and_save_model(ann_ASOIAF, \"classic_ASOIAF\")\n",
    "train_and_save_model(ann_SOC, \"classic_SOC\")\n",
    "\n",
    "mdl_comb = train_and_save_model(ann_comb, \"classic_comb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_comb[1]['text'])\n",
    "feature_weights = list(zip(mdl_comb.classifier.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len([weight for weight, _ in feature_weights if weight>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "book= load_book(\"../input_books/unlabelled/warbreaker/Warbreaker.epub\")\n",
    "texts, indexes = load_chapters(book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(mdl_comb.feature_extractor(texts[4])[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mdl_comb.character_scores(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
