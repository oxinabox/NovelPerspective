{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sample_chapters import *\n",
    "from feature_extraction import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def character_scores(classifier, raw_text, feature_extractor = get_feature_vectors):\n",
    "    names, feature_vectors, vector_keys = feature_extractor(raw_text)\n",
    "    assert(len(names) == len(feature_vectors))\n",
    "    scores = classifier.predict_proba(feature_vectors)[:,1] #second index is positive class\n",
    "    return scores, names\n",
    "\n",
    "\"\"\"\n",
    "Merge the scores of characters nicknames into the real name\n",
    "\"\"\"\n",
    "def sanitize_name_scores(scores,names, nicknames2name):\n",
    "    assert(len(names) == len(scores))\n",
    "    for nickname,truename in nicknames2name.items():\n",
    "        try:\n",
    "            ind_nick = names.index(nickname)\n",
    "            try:\n",
    "                ind_true = names.index(truename)\n",
    "\n",
    "                #transfer scores over\n",
    "                scores[ind_true]+=scores[ind_nick]\n",
    "                scores[ind_nick]=0\n",
    "            except ValueError:\n",
    "                    # truename not found, rename nick\n",
    "                    names[ind_nick]=truename\n",
    "        except ValueError:\n",
    "            #nick not found in names\n",
    "            #no worries\n",
    "            pass       \n",
    "    \n",
    "\n",
    "def choose_character(classifier, raw_text, nicknames2name=dict(), feature_extractor = get_feature_vectors):\n",
    "    scores, names = character_scores(classifier, raw_text, feature_extractor)\n",
    "    sanitize_name_scores(scores,names, nicknames2name)\n",
    "    \n",
    "    return names[np.argmax(scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_binary_choice_feature_vectors(raw_text, reference_name, name2nicknames):\n",
    "    names, vectors, vector_keys = get_feature_vectors(raw_text, name2nicknames)\n",
    "    return vectors, [(name == reference_name) for name in names]\n",
    "\n",
    "def train_classifier(annotated_data, classifier, nicknames2name=dict()):\n",
    "    Xs,Ys = zip(*[get_binary_choice_feature_vectors(datum['text'],datum['character'], nicknames2name) \n",
    "                  for datum in annotated_data])\n",
    "    Xs = np.fromiter(it.chain(*Xs))\n",
    "    Ys = np.fromiter(it.chain(*Ys))\n",
    "\n",
    "    classifier.fit(Xs,Ys)\n",
    "    return classifier\n",
    "\n",
    "def run_classifier(annotated_data, classifier, nicknames2name=dict()):\n",
    "    return [choose_character(classifier, datum['text'], nicknames2name)\n",
    "            for datum in annotated_data]\n",
    "    \n",
    "        \n",
    "def test_classifier(annotated_data, classifier, nicknames2name=dict()):\n",
    "    output_characters = run_classifier(annotated_data, classifier)\n",
    "    reference_characters = [datum['character'] for datum in annotated_data]\n",
    "    return sklearn.metrics.accuracy_score(output_characters, reference_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def evaluate(annotated_data, nicknames2name, classifier=XGBClassifier(), n_splits=10):\n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):\n",
    "        train_chapters = annotated_data[train_inds]\n",
    "        test_chapters = annotated_data[test_inds]\n",
    "\n",
    "        train_classifier(train_chapters, classifier, nicknames2name)\n",
    "        score = test_classifier(test_chapters, classifier, nicknames2name)\n",
    "        \n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nicknames2name_GoT = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Robert\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "}\n",
    "  \n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_GoT = np.asarray(json.load(fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cls = train_classifier(ann_GoT, XGBClassifier(), nicknames2name_GoT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "output_characters = run_classifier(ann_GoT, cls, nicknames2name_GoT)\n",
    "reference_characters = [datum['character'] for datum in ann_GoT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.accuracy_score(output_characters, reference_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "?list.sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.122, 'before_POS_was_percent_,'),\n",
       " (0.097999997, 'rank_percent'),\n",
       " (0.092, 'occur_percent'),\n",
       " (0.082000002, 'after_POS_was_percent_.'),\n",
       " (0.074000001, 'after_POS_was_VBD'),\n",
       " (0.071999997, 'after_POS_was_percent_VBD'),\n",
       " (0.068000004, 'before_POS_was_.'),\n",
       " (0.064000003, 'rank'),\n",
       " (0.048, 'occur_count'),\n",
       " (0.039999999, 'before_POS_was_,'),\n",
       " (0.035999998, 'last_occur_percent'),\n",
       " (0.029999999, 'before_POS_was_percent_JJ'),\n",
       " (0.026000001, 'after_POS_was_percent_VBZ'),\n",
       " (0.02, 'before_POS_was_NN'),\n",
       " (0.016000001, 'after_POS_was_MD'),\n",
       " (0.014, 'after_POS_was_percent_NN'),\n",
       " (0.012, 'after_POS_was_percent_,'),\n",
       " (0.0099999998, 'last_occur_position'),\n",
       " (0.0099999998, \"before_POS_was_percent_''\"),\n",
       " (0.0080000004, 'before_POS_was_percent_.'),\n",
       " (0.0080000004, 'after_POS_was_percent_CC'),\n",
       " (0.0060000001, 'before_POS_was_percent_WRB'),\n",
       " (0.0060000001, 'before_POS_was_percent_VBN'),\n",
       " (0.0060000001, 'before_POS_was_percent_VBD'),\n",
       " (0.0060000001, 'before_POS_was_percent_NNP'),\n",
       " (0.0040000002, 'before_POS_was_percent_NN'),\n",
       " (0.0040000002, 'after_POS_was_percent_MD'),\n",
       " (0.0040000002, 'after_POS_was_percent_IN'),\n",
       " (0.0020000001, 'before_POS_was_percent_VB'),\n",
       " (0.0020000001, 'before_POS_was_percent_CC'),\n",
       " (0.0020000001, 'before_POS_was_JJ'),\n",
       " (0.0020000001, 'after_POS_was_percent_TO'),\n",
       " (0.0020000001, 'after_POS_was_percent_RB'),\n",
       " (0.0020000001, 'after_POS_was_NN'),\n",
       " (0.0020000001, 'after_POS_was_.'),\n",
       " (0.0, 'first_occur_position'),\n",
       " (0.0, 'first_occur_percent'),\n",
       " (0.0, 'before_POS_was_percent_``'),\n",
       " (0.0, 'before_POS_was_percent_WP$'),\n",
       " (0.0, 'before_POS_was_percent_WP'),\n",
       " (0.0, 'before_POS_was_percent_WDT'),\n",
       " (0.0, 'before_POS_was_percent_VBZ'),\n",
       " (0.0, 'before_POS_was_percent_VBP'),\n",
       " (0.0, 'before_POS_was_percent_VBG'),\n",
       " (0.0, 'before_POS_was_percent_UH'),\n",
       " (0.0, 'before_POS_was_percent_TO'),\n",
       " (0.0, 'before_POS_was_percent_SYM'),\n",
       " (0.0, 'before_POS_was_percent_RP'),\n",
       " (0.0, 'before_POS_was_percent_RBS'),\n",
       " (0.0, 'before_POS_was_percent_RBR'),\n",
       " (0.0, 'before_POS_was_percent_RB'),\n",
       " (0.0, 'before_POS_was_percent_PRP$'),\n",
       " (0.0, 'before_POS_was_percent_PRP'),\n",
       " (0.0, 'before_POS_was_percent_POS'),\n",
       " (0.0, 'before_POS_was_percent_PDT'),\n",
       " (0.0, 'before_POS_was_percent_PAD'),\n",
       " (0.0, 'before_POS_was_percent_NNS'),\n",
       " (0.0, 'before_POS_was_percent_NNPS'),\n",
       " (0.0, 'before_POS_was_percent_NE'),\n",
       " (0.0, 'before_POS_was_percent_MD'),\n",
       " (0.0, 'before_POS_was_percent_LS'),\n",
       " (0.0, 'before_POS_was_percent_JJS'),\n",
       " (0.0, 'before_POS_was_percent_JJR'),\n",
       " (0.0, 'before_POS_was_percent_IN'),\n",
       " (0.0, 'before_POS_was_percent_FW'),\n",
       " (0.0, 'before_POS_was_percent_EX'),\n",
       " (0.0, 'before_POS_was_percent_DT'),\n",
       " (0.0, 'before_POS_was_percent_CD'),\n",
       " (0.0, 'before_POS_was_percent_:'),\n",
       " (0.0, 'before_POS_was_percent_--'),\n",
       " (0.0, 'before_POS_was_percent_)'),\n",
       " (0.0, 'before_POS_was_percent_('),\n",
       " (0.0, 'before_POS_was_percent_$'),\n",
       " (0.0, 'before_POS_was_percent_#'),\n",
       " (0.0, 'before_POS_was_``'),\n",
       " (0.0, 'before_POS_was_WRB'),\n",
       " (0.0, 'before_POS_was_WP$'),\n",
       " (0.0, 'before_POS_was_WP'),\n",
       " (0.0, 'before_POS_was_WDT'),\n",
       " (0.0, 'before_POS_was_VBZ'),\n",
       " (0.0, 'before_POS_was_VBP'),\n",
       " (0.0, 'before_POS_was_VBN'),\n",
       " (0.0, 'before_POS_was_VBG'),\n",
       " (0.0, 'before_POS_was_VBD'),\n",
       " (0.0, 'before_POS_was_VB'),\n",
       " (0.0, 'before_POS_was_UH'),\n",
       " (0.0, 'before_POS_was_TO'),\n",
       " (0.0, 'before_POS_was_SYM'),\n",
       " (0.0, 'before_POS_was_RP'),\n",
       " (0.0, 'before_POS_was_RBS'),\n",
       " (0.0, 'before_POS_was_RBR'),\n",
       " (0.0, 'before_POS_was_RB'),\n",
       " (0.0, 'before_POS_was_PRP$'),\n",
       " (0.0, 'before_POS_was_PRP'),\n",
       " (0.0, 'before_POS_was_POS'),\n",
       " (0.0, 'before_POS_was_PDT'),\n",
       " (0.0, 'before_POS_was_PAD'),\n",
       " (0.0, 'before_POS_was_NNS'),\n",
       " (0.0, 'before_POS_was_NNPS'),\n",
       " (0.0, 'before_POS_was_NNP'),\n",
       " (0.0, 'before_POS_was_NE'),\n",
       " (0.0, 'before_POS_was_MD'),\n",
       " (0.0, 'before_POS_was_LS'),\n",
       " (0.0, 'before_POS_was_JJS'),\n",
       " (0.0, 'before_POS_was_JJR'),\n",
       " (0.0, 'before_POS_was_IN'),\n",
       " (0.0, 'before_POS_was_FW'),\n",
       " (0.0, 'before_POS_was_EX'),\n",
       " (0.0, 'before_POS_was_DT'),\n",
       " (0.0, 'before_POS_was_CD'),\n",
       " (0.0, 'before_POS_was_CC'),\n",
       " (0.0, 'before_POS_was_:'),\n",
       " (0.0, 'before_POS_was_--'),\n",
       " (0.0, 'before_POS_was_)'),\n",
       " (0.0, 'before_POS_was_('),\n",
       " (0.0, \"before_POS_was_''\"),\n",
       " (0.0, 'before_POS_was_$'),\n",
       " (0.0, 'before_POS_was_#'),\n",
       " (0.0, 'after_POS_was_percent_``'),\n",
       " (0.0, 'after_POS_was_percent_WRB'),\n",
       " (0.0, 'after_POS_was_percent_WP$'),\n",
       " (0.0, 'after_POS_was_percent_WP'),\n",
       " (0.0, 'after_POS_was_percent_WDT'),\n",
       " (0.0, 'after_POS_was_percent_VBP'),\n",
       " (0.0, 'after_POS_was_percent_VBN'),\n",
       " (0.0, 'after_POS_was_percent_VBG'),\n",
       " (0.0, 'after_POS_was_percent_VB'),\n",
       " (0.0, 'after_POS_was_percent_UH'),\n",
       " (0.0, 'after_POS_was_percent_SYM'),\n",
       " (0.0, 'after_POS_was_percent_RP'),\n",
       " (0.0, 'after_POS_was_percent_RBS'),\n",
       " (0.0, 'after_POS_was_percent_RBR'),\n",
       " (0.0, 'after_POS_was_percent_PRP$'),\n",
       " (0.0, 'after_POS_was_percent_PRP'),\n",
       " (0.0, 'after_POS_was_percent_POS'),\n",
       " (0.0, 'after_POS_was_percent_PDT'),\n",
       " (0.0, 'after_POS_was_percent_PAD'),\n",
       " (0.0, 'after_POS_was_percent_NNS'),\n",
       " (0.0, 'after_POS_was_percent_NNPS'),\n",
       " (0.0, 'after_POS_was_percent_NNP'),\n",
       " (0.0, 'after_POS_was_percent_NE'),\n",
       " (0.0, 'after_POS_was_percent_LS'),\n",
       " (0.0, 'after_POS_was_percent_JJS'),\n",
       " (0.0, 'after_POS_was_percent_JJR'),\n",
       " (0.0, 'after_POS_was_percent_JJ'),\n",
       " (0.0, 'after_POS_was_percent_FW'),\n",
       " (0.0, 'after_POS_was_percent_EX'),\n",
       " (0.0, 'after_POS_was_percent_DT'),\n",
       " (0.0, 'after_POS_was_percent_CD'),\n",
       " (0.0, 'after_POS_was_percent_:'),\n",
       " (0.0, 'after_POS_was_percent_--'),\n",
       " (0.0, 'after_POS_was_percent_)'),\n",
       " (0.0, 'after_POS_was_percent_('),\n",
       " (0.0, \"after_POS_was_percent_''\"),\n",
       " (0.0, 'after_POS_was_percent_$'),\n",
       " (0.0, 'after_POS_was_percent_#'),\n",
       " (0.0, 'after_POS_was_``'),\n",
       " (0.0, 'after_POS_was_WRB'),\n",
       " (0.0, 'after_POS_was_WP$'),\n",
       " (0.0, 'after_POS_was_WP'),\n",
       " (0.0, 'after_POS_was_WDT'),\n",
       " (0.0, 'after_POS_was_VBZ'),\n",
       " (0.0, 'after_POS_was_VBP'),\n",
       " (0.0, 'after_POS_was_VBN'),\n",
       " (0.0, 'after_POS_was_VBG'),\n",
       " (0.0, 'after_POS_was_VB'),\n",
       " (0.0, 'after_POS_was_UH'),\n",
       " (0.0, 'after_POS_was_TO'),\n",
       " (0.0, 'after_POS_was_SYM'),\n",
       " (0.0, 'after_POS_was_RP'),\n",
       " (0.0, 'after_POS_was_RBS'),\n",
       " (0.0, 'after_POS_was_RBR'),\n",
       " (0.0, 'after_POS_was_RB'),\n",
       " (0.0, 'after_POS_was_PRP$'),\n",
       " (0.0, 'after_POS_was_PRP'),\n",
       " (0.0, 'after_POS_was_POS'),\n",
       " (0.0, 'after_POS_was_PDT'),\n",
       " (0.0, 'after_POS_was_PAD'),\n",
       " (0.0, 'after_POS_was_NNS'),\n",
       " (0.0, 'after_POS_was_NNPS'),\n",
       " (0.0, 'after_POS_was_NNP'),\n",
       " (0.0, 'after_POS_was_NE'),\n",
       " (0.0, 'after_POS_was_LS'),\n",
       " (0.0, 'after_POS_was_JJS'),\n",
       " (0.0, 'after_POS_was_JJR'),\n",
       " (0.0, 'after_POS_was_JJ'),\n",
       " (0.0, 'after_POS_was_IN'),\n",
       " (0.0, 'after_POS_was_FW'),\n",
       " (0.0, 'after_POS_was_EX'),\n",
       " (0.0, 'after_POS_was_DT'),\n",
       " (0.0, 'after_POS_was_CD'),\n",
       " (0.0, 'after_POS_was_CC'),\n",
       " (0.0, 'after_POS_was_:'),\n",
       " (0.0, 'after_POS_was_--'),\n",
       " (0.0, 'after_POS_was_,'),\n",
       " (0.0, 'after_POS_was_)'),\n",
       " (0.0, 'after_POS_was_('),\n",
       " (0.0, \"after_POS_was_''\"),\n",
       " (0.0, 'after_POS_was_$'),\n",
       " (0.0, 'after_POS_was_#')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_GoT[1]['text'])\n",
    "feature_weights = list(zip(cls.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.006,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.064,  0.   ,  0.   ,  0.   ,  0.03 ,\n",
       "        0.006,  0.   ,  0.   ,  0.   ,  0.008,  0.   ,  0.002,  0.   ,\n",
       "        0.   ,  0.098,  0.004,  0.   ,  0.01 ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.004,  0.   ,  0.   ,  0.   ,\n",
       "        0.04 ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.014,  0.   ,  0.   ,  0.   ,  0.072,\n",
       "        0.074,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.004,\n",
       "        0.   ,  0.006,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.016,  0.002,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.026,\n",
       "        0.   ,  0.   ,  0.01 ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.002,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.002,  0.092,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.048,  0.   ,  0.   ,  0.002,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.006,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.068,  0.002,  0.   ,  0.036,  0.082,  0.012,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.122,  0.   ,  0.   ,\n",
       "        0.   ,  0.008,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.   ,  0.   ,  0.02 ,  0.   ,  0.   ,  0.   ,  0.   ,\n",
       "        0.   ,  0.002,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ,  0.   ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "scores = evaluate(ann_GoT, nicknames2name_GoT, XGBClassifier(n_estimators=100))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"../flat_data/Warbreaker.json\",\"r\") as fh:\n",
    "    warbreaker = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "warbreaker_characters = run_classifier(warbreaker, cls)\n",
    "ann_warbreaker = [(char, datum['text'][1:500]) for char,datum in zip(warbreaker_characters, warbreaker)]\n",
    "ann_warbreaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for imp, name in zip(classifier.feature_importances_, FeatureVec().keys()):\n",
    "    print(name, \"\\t\", imp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image  \n",
    "from sklearn.externals.six import StringIO  \n",
    "import pydotplus as pydot\n",
    "\n",
    "dot_data = StringIO()  \n",
    "sklearn.tree.export_graphviz(classifier, out_file=dot_data,  \n",
    "                     feature_names=list(FeatureVec().keys()),  \n",
    "                     #class_names=iris.target_names,  \n",
    "                     filled=True, rounded=True,  \n",
    "                     special_characters=True)  \n",
    "graph = pydot.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
