{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sample_chapters import *\n",
    "from feature_extraction import *\n",
    "from classify import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_characters(annotated_data):\n",
    "    full_characters = np.asarray([datum['character'] for datum in annotated_data])\n",
    "    full_texts = np.asarray([datum['text'] for datum in annotated_data])\n",
    "    return full_texts, full_characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def xval_evaluate(annotated_data, solver, n_splits=10, metric=accuracy_score, mute=True):\n",
    "    \n",
    "    full_texts, full_characters = extract_texts_and_characters(annotated_data)\n",
    "    \n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):        \n",
    "        train_ann_data = annotated_data[train_inds]\n",
    "        test_ann_data = annotated_data[test_inds]\n",
    "\n",
    "        score = train_test_evaluate(train_ann_data, test_ann_data, solver, n_splits, metric)\n",
    "        \n",
    "        if not(mute):\n",
    "            print(score)\n",
    "            \n",
    "        scores.append(score)\n",
    "    return np.mean(scores, axis=0)\n",
    "\n",
    "\n",
    "def evaluate(train_ann_data, test_ann_data, solver, n_splits=10, metric=accuracy_score):   \n",
    "    train_texts, train_characters = extract_texts_and_characters(train_ann_data)\n",
    "    test_texts, test_characters = extract_texts_and_characters(test_ann_data)\n",
    "\n",
    "    solver.train(train_texts, train_characters)\n",
    "    score = solver.test(test_texts, test_characters, metric=metric)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:  348 92 256\n",
      "POVs:  22 7 15\n"
     ]
    }
   ],
   "source": [
    "nicknames2name_comb = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "    \"Rollins\" : \"Pekka\"\n",
    "}\n",
    "\n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_ASOIAF = np.asarray(json.load(fh))\n",
    "    \n",
    "    \n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.asarray(json.load(fh))\n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.hstack([ann_SOC, np.asarray(json.load(fh))])\n",
    "\n",
    "ann_comb = np.hstack([ann_SOC, ann_ASOIAF])\n",
    "\n",
    "np.random.shuffle(ann_ASOIAF)\n",
    "np.random.shuffle(ann_SOC)\n",
    "np.random.shuffle(ann_comb)\n",
    "print(\"lengths: \", len(ann_comb), len(ann_SOC), len(ann_ASOIAF))\n",
    "print(\"POVs: \", *[len(np.unique(extract_texts_and_characters(ann)[1])) for ann in (ann_comb, ann_SOC, ann_ASOIAF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Inej', 'Jesper', 'Joost', 'Kaz', 'Matthias', 'Nina', 'Pekka'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(extract_texts_and_characters(ann_SOC)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validation_evaluate(ann_ASOIAF, MLCharacterSolver(XGBClassifier(), nicknames2name_comb),\n",
    "                                  metric=lambda tt,pp: precision_recall_fscore_support(tt,pp, average='macro', warn_for={})[0:3])\n",
    "np.mean(scores, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First Mentioned', 'ASOIAF')  0.25\n",
      "('First Mentioned', 'SOC')  0.3695652173913043\n",
      "('ML Classical Features Trained on ASOIAF', 'SOC')  0.9130434782608695\n",
      "('ML Classical Features Trained on SOC', 'ASOIAF')  0.91796875\n",
      "('Most Commonly Mentioned', 'ASOIAF')  0.91015625\n",
      "('Most Commonly Mentioned', 'SOC')  0.782608695652174\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(First Mentioned, ASOIAF)</th>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(First Mentioned, SOC)</th>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ML Classical Features Trained on ASOIAF, SOC)</th>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ML Classical Features Trained on SOC, ASOIAF)</th>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Most Commonly Mentioned, ASOIAF)</th>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Most Commonly Mentioned, SOC)</th>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     Acc\n",
       "(First Mentioned, ASOIAF)                       0.250000\n",
       "(First Mentioned, SOC)                          0.369565\n",
       "(ML Classical Features Trained on ASOIAF, SOC)  0.913043\n",
       "(ML Classical Features Trained on SOC, ASOIAF)  0.917969\n",
       "(Most Commonly Mentioned, ASOIAF)               0.910156\n",
       "(Most Commonly Mentioned, SOC)                  0.782609"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_mdl = MLCharacterSolver(XGBClassifier(), nicknames2name_comb)\n",
    "FM_mdl = FirstMentionedSolver(nicknames2name_comb)\n",
    "MC_mdl = MostMentionedSolver(nicknames2name_comb)\n",
    "\n",
    "\n",
    "program = {\n",
    "    (\"ML Classical Features Trained on SOC\",\"ASOIAF\"): (ann_SOC, ann_ASOIAF, ML_mdl) ,\n",
    "    (\"ML Classical Features Trained on ASOIAF\",\"SOC\"): (ann_ASOIAF, ann_SOC, ML_mdl),   \n",
    "    (\"First Mentioned\",\"SOC\") :                        ([], ann_SOC, FM_mdl),\n",
    "    (\"First Mentioned\",\"ASOIAF\"):                      ([], ann_ASOIAF, FM_mdl),\n",
    "    (\"Most Commonly Mentioned\",\"SOC\"):                 ([], ann_SOC, MC_mdl),\n",
    "    (\"Most Commonly Mentioned\",\"ASOIAF\"):              ([], ann_ASOIAF, MC_mdl),\n",
    "}\n",
    "\n",
    "\n",
    "res = pd.DataFrame(index=program.keys())\n",
    "res.sort_index(inplace=True)\n",
    "\n",
    "for ind in res.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = evaluate(*program[ind])\n",
    "    res.loc[ind, \"Acc\"] = score\n",
    "    print(\" \", score)\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Evaluation\n",
    "To test how much it effects things from different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('First Mentioned', 'ASOIAF')  0.25015384615384617\n",
      "('First Mentioned', 'SOC')  0.37\n",
      "('First Mentioned', 'combined')  0.28168067226890753\n",
      "('ML Classical Features', 'ASOIAF')  0.9607692307692307\n",
      "('ML Classical Features', 'SOC')  0.9777777777777779\n",
      "('ML Classical Features', 'combined')  0.9598319327731092\n",
      "('Most Commonly Mentioned', 'ASOIAF')  0.9099999999999999\n",
      "('Most Commonly Mentioned', 'SOC')  0.7844444444444444\n",
      "('Most Commonly Mentioned', 'combined')  0.876470588235294\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(First Mentioned, ASOIAF)</th>\n",
       "      <td>0.250154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(First Mentioned, SOC)</th>\n",
       "      <td>0.370000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(First Mentioned, combined)</th>\n",
       "      <td>0.281681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ML Classical Features, ASOIAF)</th>\n",
       "      <td>0.960769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ML Classical Features, SOC)</th>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ML Classical Features, combined)</th>\n",
       "      <td>0.959832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Most Commonly Mentioned, ASOIAF)</th>\n",
       "      <td>0.910000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Most Commonly Mentioned, SOC)</th>\n",
       "      <td>0.784444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(Most Commonly Mentioned, combined)</th>\n",
       "      <td>0.876471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Acc\n",
       "(First Mentioned, ASOIAF)            0.250154\n",
       "(First Mentioned, SOC)               0.370000\n",
       "(First Mentioned, combined)          0.281681\n",
       "(ML Classical Features, ASOIAF)      0.960769\n",
       "(ML Classical Features, SOC)         0.977778\n",
       "(ML Classical Features, combined)    0.959832\n",
       "(Most Commonly Mentioned, ASOIAF)    0.910000\n",
       "(Most Commonly Mentioned, SOC)       0.784444\n",
       "(Most Commonly Mentioned, combined)  0.876471"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program = {\n",
    "    (\"ML Classical Features\",\"ASOIAF\"):                (ann_ASOIAF, ML_mdl),\n",
    "    (\"ML Classical Features\",\"SOC\"):                   (ann_SOC, ML_mdl),\n",
    "    (\"ML Classical Features\",\"combined\"):              (ann_comb, ML_mdl),\n",
    "    \n",
    "    (\"First Mentioned\",\"SOC\") :                        (ann_SOC, FM_mdl),\n",
    "    (\"First Mentioned\",\"ASOIAF\"):                      (ann_ASOIAF, FM_mdl),\n",
    "    (\"First Mentioned\",\"combined\"):                    (ann_comb, FM_mdl),\n",
    "    \n",
    "    (\"Most Commonly Mentioned\",\"SOC\"):                 (ann_SOC, MC_mdl),\n",
    "    (\"Most Commonly Mentioned\",\"ASOIAF\"):              (ann_ASOIAF, MC_mdl),\n",
    "    (\"Most Commonly Mentioned\",\"combined\"):            (ann_comb, MC_mdl),\n",
    "}\n",
    "\n",
    "\n",
    "res_xval = pd.DataFrame(index=program.keys())\n",
    "res_xval.sort_index(inplace=True)\n",
    "\n",
    "for ind in res_xval.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = xval_evaluate(*program[ind]) \n",
    "    res_xval.loc[ind, \"Acc\"] = score\n",
    "    print(\" \", score)\n",
    "    \n",
    "res_xval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = train_classifier(*extract_texts_and_characters(ann_ASOIAF), \n",
    "                       classifier=XGBClassifier())\n",
    "\n",
    "output_characters = list(run_classifier(extract_texts_and_characters(ann_ASOIAF)[0], \n",
    "                       classifier=cls,\n",
    "                       nicknames2name=nicknames2name_ASOIAF))\n",
    "reference_characters = [datum['character'] for datum in ann_ASOIAF]\n",
    "\n",
    "print(\"acc: \", sklearn.metrics.accuracy_score(output_characters, reference_characters))\n",
    "\n",
    "joblib.dump(cls, \"../trained_models/ASOIAF-no-headings.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_ASOIAF[1]['text'])\n",
    "feature_weights = list(zip(cls.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = evaluate(ann_ASOIAF, nicknames2name_ASOIAF, XGBClassifier(n_estimators=100))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../flat_data/Warbreaker.json\",\"r\") as fh:\n",
    "    warbreaker = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = joblib.load(\"trained_models/ASOIAF-no-headings.pkl\")\n",
    "warbreaker_characters = run_classifier(extract_texts_and_characters(warbreaker)[0], \n",
    "                       classifier=cls,)\n",
    "ann_warbreaker = [(char, datum['text'][1:125]) for char,datum in zip(warbreaker_characters, warbreaker)]\n",
    "ann_warbreaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp, name in zip(classifier.feature_importances_, FeatureVec().keys()):\n",
    "    print(name, \"\\t\", imp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
