{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sample_chapters import *\n",
    "from feature_extraction import *\n",
    "from classify import *\n",
    "from book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_characters(annotated_data):\n",
    "    full_characters = np.asarray([datum['character'] for datum in annotated_data])\n",
    "    full_texts = np.asarray([datum['text'] for datum in annotated_data])\n",
    "    return full_texts, full_characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def xval_evaluate(annotated_data, solver, n_splits=10, metric=accuracy_score, mute=True):\n",
    "    \n",
    "    full_texts, full_characters = extract_texts_and_characters(annotated_data)\n",
    "    \n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):        \n",
    "        train_ann_data = annotated_data[train_inds]\n",
    "        test_ann_data = annotated_data[test_inds]\n",
    "\n",
    "        score = train_test_evaluate(train_ann_data, test_ann_data, solver, n_splits, metric)\n",
    "        \n",
    "        if not(mute):\n",
    "            print(score)\n",
    "            \n",
    "        scores.append(score)\n",
    "    return np.mean(scores, axis=0)\n",
    "\n",
    "\n",
    "def evaluate(train_ann_data, test_ann_data, solver, n_splits=10, metric=accuracy_score):   \n",
    "    train_texts, train_characters = extract_texts_and_characters(train_ann_data)\n",
    "    test_texts, test_characters = extract_texts_and_characters(test_ann_data)\n",
    "\n",
    "    solver.train(train_texts, train_characters)\n",
    "    score = solver.test(test_texts, test_characters, metric=metric)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:  348 92 256\n",
      "POVs:  22 7 15\n"
     ]
    }
   ],
   "source": [
    "nicknames2name_comb = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "    \"Rollins\" : \"Pekka\"\n",
    "}\n",
    "\n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_ASOIAF = np.asarray(json.load(fh))\n",
    "    \n",
    "    \n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.asarray(json.load(fh))\n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.hstack([ann_SOC, np.asarray(json.load(fh))])\n",
    "\n",
    "ann_comb = np.hstack([ann_SOC, ann_ASOIAF])\n",
    "\n",
    "np.random.shuffle(ann_ASOIAF)\n",
    "np.random.shuffle(ann_SOC)\n",
    "np.random.shuffle(ann_comb)\n",
    "print(\"lengths: \", len(ann_comb), len(ann_SOC), len(ann_ASOIAF))\n",
    "print(\"POVs: \", *[len(np.unique(extract_texts_and_characters(ann)[1])) for ann in (ann_comb, ann_SOC, ann_ASOIAF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Inej', 'Jesper', 'Joost', 'Kaz', 'Matthias', 'Nina', 'Pekka'],\n",
       "      dtype='<U8')"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(extract_texts_and_characters(ann_SOC)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_validation_evaluate(ann_ASOIAF, MLCharacterSolver(XGBClassifier(), nicknames2name_comb),\n",
    "                                  metric=lambda tt,pp: precision_recall_fscore_support(tt,pp, average='macro', warn_for={})[0:3])\n",
    "np.mean(scores, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def all_metrics(tt,pp):\n",
    "    prf = precision_recall_fscore_support(tt,pp, average='weighted', warn_for={})[0:3]\n",
    "    acc = accuracy_score(tt,pp)\n",
    "    return np.hstack([prf, acc])\n",
    "\n",
    "all_metrics_names = [\"P\", \"R\", \"F1\", \"Acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASOIAF', 'First Mentioned')  [0.08571298 0.25       0.12451888 0.25      ]\n",
      "('ASOIAF', 'ML Classical Features Trained on SOC')  [0.86209911 0.91796875 0.88736337 0.91796875]\n",
      "('ASOIAF', 'Most Commonly Mentioned')  [0.86042302 0.91015625 0.88016394 0.91015625]\n",
      "('SOC', 'First Mentioned')  [0.20992534 0.36956522 0.26519616 0.36956522]\n",
      "('SOC', 'ML Classical Features Trained on ASOIAF')  [0.87439614 0.91304348 0.89258312 0.91304348]\n",
      "('SOC', 'Most Commonly Mentioned')  [0.73781291 0.7826087  0.74923274 0.7826087 ]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, First Mentioned)</th>\n",
       "      <td>0.085713</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.124519</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, ML Classical Features Trained on SOC)</th>\n",
       "      <td>0.862099</td>\n",
       "      <td>0.917969</td>\n",
       "      <td>0.887363</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, Most Commonly Mentioned)</th>\n",
       "      <td>0.860423</td>\n",
       "      <td>0.910156</td>\n",
       "      <td>0.880164</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, First Mentioned)</th>\n",
       "      <td>0.209925</td>\n",
       "      <td>0.369565</td>\n",
       "      <td>0.265196</td>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, ML Classical Features Trained on ASOIAF)</th>\n",
       "      <td>0.874396</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.892583</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, Most Commonly Mentioned)</th>\n",
       "      <td>0.737813</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.749233</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       P         R        F1  \\\n",
       "(ASOIAF, First Mentioned)                       0.085713      0.25  0.124519   \n",
       "(ASOIAF, ML Classical Features Trained on SOC)  0.862099  0.917969  0.887363   \n",
       "(ASOIAF, Most Commonly Mentioned)               0.860423  0.910156  0.880164   \n",
       "(SOC, First Mentioned)                          0.209925  0.369565  0.265196   \n",
       "(SOC, ML Classical Features Trained on ASOIAF)  0.874396  0.913043  0.892583   \n",
       "(SOC, Most Commonly Mentioned)                  0.737813  0.782609  0.749233   \n",
       "\n",
       "                                                     Acc  \n",
       "(ASOIAF, First Mentioned)                           0.25  \n",
       "(ASOIAF, ML Classical Features Trained on SOC)  0.917969  \n",
       "(ASOIAF, Most Commonly Mentioned)               0.910156  \n",
       "(SOC, First Mentioned)                          0.369565  \n",
       "(SOC, ML Classical Features Trained on ASOIAF)  0.913043  \n",
       "(SOC, Most Commonly Mentioned)                  0.782609  "
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_mdl = MLCharacterSolver(XGBClassifier(), nicknames2name_comb)\n",
    "FM_mdl = FirstMentionedSolver(nicknames2name_comb)\n",
    "MC_mdl = MostMentionedSolver(nicknames2name_comb)\n",
    "\n",
    "\n",
    "program = {\n",
    "    (\"ASOIAF\", \"ML Classical Features Trained on SOC\"): (ann_SOC, ann_ASOIAF, ML_mdl) ,\n",
    "    (\"SOC\", \"ML Classical Features Trained on ASOIAF\"): (ann_ASOIAF, ann_SOC, ML_mdl),   \n",
    "    (\"SOC\", \"First Mentioned\") :                        ([], ann_SOC, FM_mdl),\n",
    "    (\"ASOIAF\", \"First Mentioned\"):                      ([], ann_ASOIAF, FM_mdl),\n",
    "    (\"SOC\", \"Most Commonly Mentioned\"):                 ([], ann_SOC, MC_mdl),\n",
    "    (\"ASOIAF\", \"Most Commonly Mentioned\"):              ([], ann_ASOIAF, MC_mdl),\n",
    "}\n",
    "\n",
    "\n",
    "res = pd.DataFrame(index=program.keys(), columns = all_metrics_names)\n",
    "res.sort_index(inplace=True)\n",
    "\n",
    "for ind in res.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = evaluate(*program[ind], metric=all_metrics)\n",
    "    res.loc[ind,:] = score\n",
    "    print(\" \", score)\n",
    "    \n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Evaluation\n",
    "To test how much it effects things from different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASOIAF', 'First Mentioned')  [0.15136777 0.25015385 0.17685377 0.25015385]\n",
      "('ASOIAF', 'ML Classical Features')  [0.94408791 0.96076923 0.94870154 0.96076923]\n",
      "('ASOIAF', 'Most Commonly Mentioned')  [0.87444689 0.91       0.88528164 0.91      ]\n",
      "('SOC', 'First Mentioned')  [0.32287037 0.37       0.32645503 0.37      ]\n",
      "('SOC', 'ML Classical Features')  [1.         0.97777778 0.98333333 0.97777778]\n",
      "('SOC', 'Most Commonly Mentioned')  [0.80657407 0.78444444 0.76867725 0.78444444]\n",
      "('combined', 'First Mentioned')  [0.17205602 0.28168067 0.20472015 0.28168067]\n",
      "('combined', 'ML Classical Features')  [0.9445042  0.95983193 0.94888329 0.95983193]\n",
      "('combined', 'Most Commonly Mentioned')  [0.8532521  0.87647059 0.85707483 0.87647059]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, First Mentioned)</th>\n",
       "      <td>0.151368</td>\n",
       "      <td>0.250154</td>\n",
       "      <td>0.176854</td>\n",
       "      <td>0.250154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, ML Classical Features)</th>\n",
       "      <td>0.944088</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.948702</td>\n",
       "      <td>0.960769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, Most Commonly Mentioned)</th>\n",
       "      <td>0.874447</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.885282</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, First Mentioned)</th>\n",
       "      <td>0.32287</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.326455</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, ML Classical Features)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, Most Commonly Mentioned)</th>\n",
       "      <td>0.806574</td>\n",
       "      <td>0.784444</td>\n",
       "      <td>0.768677</td>\n",
       "      <td>0.784444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, First Mentioned)</th>\n",
       "      <td>0.172056</td>\n",
       "      <td>0.281681</td>\n",
       "      <td>0.20472</td>\n",
       "      <td>0.281681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, ML Classical Features)</th>\n",
       "      <td>0.944504</td>\n",
       "      <td>0.959832</td>\n",
       "      <td>0.948883</td>\n",
       "      <td>0.959832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, Most Commonly Mentioned)</th>\n",
       "      <td>0.853252</td>\n",
       "      <td>0.876471</td>\n",
       "      <td>0.857075</td>\n",
       "      <td>0.876471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            P         R        F1       Acc\n",
       "(ASOIAF, First Mentioned)            0.151368  0.250154  0.176854  0.250154\n",
       "(ASOIAF, ML Classical Features)      0.944088  0.960769  0.948702  0.960769\n",
       "(ASOIAF, Most Commonly Mentioned)    0.874447      0.91  0.885282      0.91\n",
       "(SOC, First Mentioned)                0.32287      0.37  0.326455      0.37\n",
       "(SOC, ML Classical Features)                1  0.977778  0.983333  0.977778\n",
       "(SOC, Most Commonly Mentioned)       0.806574  0.784444  0.768677  0.784444\n",
       "(combined, First Mentioned)          0.172056  0.281681   0.20472  0.281681\n",
       "(combined, ML Classical Features)    0.944504  0.959832  0.948883  0.959832\n",
       "(combined, Most Commonly Mentioned)  0.853252  0.876471  0.857075  0.876471"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program = {\n",
    "    (\"ASOIAF\", \"ML Classical Features\"):                (ann_ASOIAF, ML_mdl),\n",
    "    (\"SOC\", \"ML Classical Features\"):                   (ann_SOC, ML_mdl),\n",
    "    (\"combined\", \"ML Classical Features\"):              (ann_comb, ML_mdl),\n",
    "    \n",
    "    (\"SOC\", \"First Mentioned\"):                         (ann_SOC, FM_mdl),\n",
    "    (\"ASOIAF\", \"First Mentioned\"):                      (ann_ASOIAF, FM_mdl),\n",
    "    (\"combined\", \"First Mentioned\"):                    (ann_comb, FM_mdl),\n",
    "    \n",
    "    (\"SOC\", \"Most Commonly Mentioned\"):                 (ann_SOC, MC_mdl),\n",
    "    (\"ASOIAF\", \"Most Commonly Mentioned\"):              (ann_ASOIAF, MC_mdl),\n",
    "    (\"combined\", \"Most Commonly Mentioned\"):            (ann_comb, MC_mdl),\n",
    "}\n",
    "\n",
    "res_xval = pd.DataFrame(index=program.keys(), columns = all_metrics_names)\n",
    "res_xval.sort_index(inplace=True)\n",
    "\n",
    "for ind in res_xval.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = xval_evaluate(*program[ind], metric=all_metrics) \n",
    "    res_xval.loc[ind, :] = score\n",
    "    print(\" \", score)\n",
    "    \n",
    "res_xval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = train_classifier(*extract_texts_and_characters(ann_ASOIAF), \n",
    "                       classifier=XGBClassifier())\n",
    "\n",
    "output_characters = list(run_classifier(extract_texts_and_characters(ann_ASOIAF)[0], \n",
    "                       classifier=cls,\n",
    "                       nicknames2name=nicknames2name_ASOIAF))\n",
    "reference_characters = [datum['character'] for datum in ann_ASOIAF]\n",
    "\n",
    "print(\"acc: \", sklearn.metrics.accuracy_score(output_characters, reference_characters))\n",
    "\n",
    "joblib.dump(cls, \"../trained_models/ASOIAF-no-headings.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_ASOIAF[1]['text'])\n",
    "feature_weights = list(zip(cls.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = evaluate(ann_ASOIAF, nicknames2name_ASOIAF, XGBClassifier(n_estimators=100))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../flat_data/Warbreaker.json\",\"r\") as fh:\n",
    "    warbreaker = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = joblib.load(\"trained_models/ASOIAF-no-headings.pkl\")\n",
    "warbreaker_characters = run_classifier(extract_texts_and_characters(warbreaker)[0], \n",
    "                       classifier=cls,)\n",
    "ann_warbreaker = [(char, datum['text'][1:125]) for char,datum in zip(warbreaker_characters, warbreaker)]\n",
    "ann_warbreaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp, name in zip(classifier.feature_importances_, FeatureVec().keys()):\n",
    "    print(name, \"\\t\", imp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"//*[((name()='h1' or name()='h2') and re:test(., '\\s*((chapter|book|section|part)\\s+)|((prolog|prologue|epilogue)(\\s+|$))', 'i')) or @class = 'chapter' or @class = 'scenebreak']\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//*[((name()='h1' or name()='h2') and re:test(., '\\s*((chapter|book|section|part)\\s+)|((prolog|prologue|epilogue)(\\s+|$))', 'i')) or @class = 'chapter' or @class = 'scenebreak']\n"
     ]
    }
   ],
   "source": [
    "print(\"\"\"//*[((name()='h1' or name()='h2') and re:test(., '\\s*((chapter|book|section|part)\\s+)|((prolog|prologue|epilogue)(\\s+|$))', 'i')) or @class = 'chapter' or @class = 'scenebreak']\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[No Characters Detected]',\n",
       " 'WARBREAKER',\n",
       " 'Dedication For Emily Sanderson',\n",
       " 'Kuntry Bumpken',\n",
       " 'Vasher',\n",
       " 'Siri',\n",
       " 'Vivenna',\n",
       " 'Lightsong',\n",
       " 'Siri',\n",
       " 'Vasher',\n",
       " 'Siri',\n",
       " 'Lightsong',\n",
       " 'Siri',\n",
       " 'Vivenna',\n",
       " 'Vivenna',\n",
       " 'Siri',\n",
       " 'Lightsong',\n",
       " 'Denth',\n",
       " 'Vivenna',\n",
       " 'Siri',\n",
       " 'Lightsong',\n",
       " 'Vivenna',\n",
       " 'Lightsong',\n",
       " 'Denth',\n",
       " 'Siri',\n",
       " 'Vasher',\n",
       " 'Denth',\n",
       " 'Mercystar',\n",
       " 'Siri',\n",
       " 'Vivenna',\n",
       " 'Lightsong',\n",
       " 'Siri',\n",
       " 'Denth',\n",
       " 'Denth',\n",
       " 'Lightsong',\n",
       " 'Vivenna',\n",
       " 'Siri',\n",
       " 'Vivenna',\n",
       " 'Siri',\n",
       " 'Denth',\n",
       " 'Siri',\n",
       " 'Denth',\n",
       " 'Lightsong',\n",
       " 'Denth',\n",
       " 'Treledees',\n",
       " 'Vivenna',\n",
       " 'Allmother',\n",
       " 'Vivenna',\n",
       " 'Siri',\n",
       " 'Of Lifeless',\n",
       " 'Vasher',\n",
       " 'Lightsong',\n",
       " 'Siri',\n",
       " 'Vivenna',\n",
       " 'Lightsong',\n",
       " 'Nightblood',\n",
       " 'Lightsong',\n",
       " 'Lightsong',\n",
       " 'Treledees',\n",
       " 'Susebron',\n",
       " 'Vasher',\n",
       " 'Lightsong',\n",
       " 'Vivenna',\n",
       " 'Vivenna',\n",
       " 'Raoden',\n",
       " 'Kelsier',\n",
       " 'Camon',\n",
       " 'Evil Librarians Alcatraz Author',\n",
       " '[No Characters Detected]']"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts, _ = load_chapters(load_book(\"../input_books/unlabelled/warbreaker/Warbreaker.epub\"))\n",
    "\n",
    "gen = MostMentionedSolver().choose_characters(texts)\n",
    "list(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
