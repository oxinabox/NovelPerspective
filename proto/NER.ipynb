{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "from sample_chapters import *\n",
    "from feature_extraction import *\n",
    "from classify import *\n",
    "from book import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_characters(annotated_data):\n",
    "    full_characters = np.asarray([datum['character'] for datum in annotated_data])\n",
    "    full_texts = np.asarray([datum['text'] for datum in annotated_data])\n",
    "    return full_texts, full_characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def xval_evaluate(annotated_data, solver, n_splits=10, metric=accuracy_score, mute=True):\n",
    "    \n",
    "    full_texts, full_characters = extract_texts_and_characters(annotated_data)\n",
    "    \n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):        \n",
    "        train_ann_data = annotated_data[train_inds]\n",
    "        test_ann_data = annotated_data[test_inds]\n",
    "\n",
    "        score = train_test_evaluate(train_ann_data, test_ann_data, solver, n_splits, metric)\n",
    "        \n",
    "        if not(mute):\n",
    "            print(score)\n",
    "            \n",
    "        scores.append(score)\n",
    "    return np.mean(scores, axis=0)\n",
    "\n",
    "\n",
    "def evaluate(train_ann_data, test_ann_data, solver, n_splits=10, metric=accuracy_score):   \n",
    "    train_texts, train_characters = extract_texts_and_characters(train_ann_data)\n",
    "    test_texts, test_characters = extract_texts_and_characters(test_ann_data)\n",
    "\n",
    "    solver.train(train_texts, train_characters)\n",
    "    score = solver.test(test_texts, test_characters, metric=metric)\n",
    "    return score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lengths:  348 92 256\n",
      "POVs:  22 7 15\n"
     ]
    }
   ],
   "source": [
    "nicknames2name_comb = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "    \"Rollins\" : \"Pekka\"\n",
    "}\n",
    "\n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_ASOIAF = np.asarray(json.load(fh))\n",
    "    \n",
    "    \n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.asarray(json.load(fh))\n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_SOC = np.hstack([ann_SOC, np.asarray(json.load(fh))])\n",
    "\n",
    "ann_comb = np.hstack([ann_SOC, ann_ASOIAF])\n",
    "\n",
    "np.random.shuffle(ann_ASOIAF)\n",
    "np.random.shuffle(ann_SOC)\n",
    "np.random.shuffle(ann_comb)\n",
    "print(\"lengths: \", len(ann_comb), len(ann_SOC), len(ann_ASOIAF))\n",
    "print(\"POVs: \", *[len(np.unique(extract_texts_and_characters(ann)[1])) for ann in (ann_comb, ann_SOC, ann_ASOIAF)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3])"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3],[1,5,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def all_metrics(tt,pp):\n",
    "    prf = precision_recall_fscore_support(tt,pp, average='macro', labels=np.unique(tt))[0:3]\n",
    "    acc = accuracy_score(tt,pp)\n",
    "    return np.hstack([prf, acc])\n",
    "\n",
    "all_metrics_names = [\"P\", \"R\", \"F1\", \"Acc\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASOIAF', 'First Mentioned')  [0.02190518 0.07219788 0.03227254 0.25      ]\n",
      "('ASOIAF', 'ML Classical Features Trained on SOC')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.46787058 0.48834536 0.47662706 0.91796875]\n",
      "('ASOIAF', 'Most Commonly Mentioned')  [0.55891593 0.58322807 0.56732114 0.91015625]\n",
      "('SOC', 'First Mentioned')  [0.1010101  0.19498747 0.13106484 0.36956522]\n",
      "('SOC', 'ML Classical Features Trained on ASOIAF')  [0.72222222 0.74691358 0.73384168 0.91304348]\n",
      "('SOC', 'Most Commonly Mentioned')  [0.53948577 0.57805326 0.55175282 0.7826087 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, First Mentioned)</th>\n",
       "      <td>0.0219052</td>\n",
       "      <td>0.0721979</td>\n",
       "      <td>0.0322725</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, ML Classical Features Trained on SOC)</th>\n",
       "      <td>0.467871</td>\n",
       "      <td>0.488345</td>\n",
       "      <td>0.476627</td>\n",
       "      <td>0.917969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, Most Commonly Mentioned)</th>\n",
       "      <td>0.558916</td>\n",
       "      <td>0.583228</td>\n",
       "      <td>0.567321</td>\n",
       "      <td>0.910156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, First Mentioned)</th>\n",
       "      <td>0.10101</td>\n",
       "      <td>0.194987</td>\n",
       "      <td>0.131065</td>\n",
       "      <td>0.369565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, ML Classical Features Trained on ASOIAF)</th>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.746914</td>\n",
       "      <td>0.733842</td>\n",
       "      <td>0.913043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, Most Commonly Mentioned)</th>\n",
       "      <td>0.539486</td>\n",
       "      <td>0.578053</td>\n",
       "      <td>0.551753</td>\n",
       "      <td>0.782609</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        P          R  \\\n",
       "(ASOIAF, First Mentioned)                       0.0219052  0.0721979   \n",
       "(ASOIAF, ML Classical Features Trained on SOC)   0.467871   0.488345   \n",
       "(ASOIAF, Most Commonly Mentioned)                0.558916   0.583228   \n",
       "(SOC, First Mentioned)                            0.10101   0.194987   \n",
       "(SOC, ML Classical Features Trained on ASOIAF)   0.722222   0.746914   \n",
       "(SOC, Most Commonly Mentioned)                   0.539486   0.578053   \n",
       "\n",
       "                                                       F1       Acc  \n",
       "(ASOIAF, First Mentioned)                       0.0322725      0.25  \n",
       "(ASOIAF, ML Classical Features Trained on SOC)   0.476627  0.917969  \n",
       "(ASOIAF, Most Commonly Mentioned)                0.567321  0.910156  \n",
       "(SOC, First Mentioned)                           0.131065  0.369565  \n",
       "(SOC, ML Classical Features Trained on ASOIAF)   0.733842  0.913043  \n",
       "(SOC, Most Commonly Mentioned)                   0.551753  0.782609  "
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ML_mdl = MLCharacterSolver(XGBClassifier(), nicknames2name_comb)\n",
    "FM_mdl = FirstMentionedSolver(nicknames2name_comb)\n",
    "MC_mdl = MostMentionedSolver(nicknames2name_comb)\n",
    "\n",
    "\n",
    "program = {\n",
    "    (\"ASOIAF\", \"ML Classical Features Trained on SOC\"): (ann_SOC, ann_ASOIAF, ML_mdl) ,\n",
    "    (\"SOC\", \"ML Classical Features Trained on ASOIAF\"): (ann_ASOIAF, ann_SOC, ML_mdl),   \n",
    "    (\"SOC\", \"First Mentioned\") :                        ([], ann_SOC, FM_mdl),\n",
    "    (\"ASOIAF\", \"First Mentioned\"):                      ([], ann_ASOIAF, FM_mdl),\n",
    "    (\"SOC\", \"Most Commonly Mentioned\"):                 ([], ann_SOC, MC_mdl),\n",
    "    (\"ASOIAF\", \"Most Commonly Mentioned\"):              ([], ann_ASOIAF, MC_mdl),\n",
    "}\n",
    "\n",
    "\n",
    "res = pd.DataFrame(index=program.keys(), columns = all_metrics_names)\n",
    "res.sort_index(inplace=True)\n",
    "\n",
    "for ind in res.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = evaluate(*program[ind], metric=all_metrics)\n",
    "    res.loc[ind,:] = score\n",
    "    print(\" \", score)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Evaluation\n",
    "To test how much it effects things from different styles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ASOIAF', 'First Mentioned')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.11669051 0.20019236 0.13732956 0.25015385]\n",
      "('ASOIAF', 'ML Classical Features')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.92700105 0.94379371 0.93134033 0.96076923]\n",
      "('ASOIAF', 'Most Commonly Mentioned')  [0.81248182 0.84622183 0.82171873 0.91      ]\n",
      "('SOC', 'First Mentioned')  [0.27833333 0.33738095 0.28857143 0.37      ]\n",
      "('SOC', 'ML Classical Features')  [1.         0.97777778 0.98333333 0.97777778]\n",
      "('SOC', 'Most Commonly Mentioned')  [0.75125    0.75875    0.73228571 0.78444444]\n",
      "('combined', 'First Mentioned')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.12824748 0.21695928 0.15304311 0.28168067]\n",
      "('combined', 'ML Classical Features')"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.4/dist-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [0.90938834 0.92889816 0.91559743 0.95983193]\n",
      "('combined', 'Most Commonly Mentioned')  [0.7859963  0.80562511 0.78858755 0.87647059]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P</th>\n",
       "      <th>R</th>\n",
       "      <th>F1</th>\n",
       "      <th>Acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, First Mentioned)</th>\n",
       "      <td>0.116691</td>\n",
       "      <td>0.200192</td>\n",
       "      <td>0.13733</td>\n",
       "      <td>0.250154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, ML Classical Features)</th>\n",
       "      <td>0.927001</td>\n",
       "      <td>0.943794</td>\n",
       "      <td>0.93134</td>\n",
       "      <td>0.960769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(ASOIAF, Most Commonly Mentioned)</th>\n",
       "      <td>0.812482</td>\n",
       "      <td>0.846222</td>\n",
       "      <td>0.821719</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, First Mentioned)</th>\n",
       "      <td>0.278333</td>\n",
       "      <td>0.337381</td>\n",
       "      <td>0.288571</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, ML Classical Features)</th>\n",
       "      <td>1</td>\n",
       "      <td>0.977778</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.977778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(SOC, Most Commonly Mentioned)</th>\n",
       "      <td>0.75125</td>\n",
       "      <td>0.75875</td>\n",
       "      <td>0.732286</td>\n",
       "      <td>0.784444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, First Mentioned)</th>\n",
       "      <td>0.128247</td>\n",
       "      <td>0.216959</td>\n",
       "      <td>0.153043</td>\n",
       "      <td>0.281681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, ML Classical Features)</th>\n",
       "      <td>0.909388</td>\n",
       "      <td>0.928898</td>\n",
       "      <td>0.915597</td>\n",
       "      <td>0.959832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(combined, Most Commonly Mentioned)</th>\n",
       "      <td>0.785996</td>\n",
       "      <td>0.805625</td>\n",
       "      <td>0.788588</td>\n",
       "      <td>0.876471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            P         R        F1       Acc\n",
       "(ASOIAF, First Mentioned)            0.116691  0.200192   0.13733  0.250154\n",
       "(ASOIAF, ML Classical Features)      0.927001  0.943794   0.93134  0.960769\n",
       "(ASOIAF, Most Commonly Mentioned)    0.812482  0.846222  0.821719      0.91\n",
       "(SOC, First Mentioned)               0.278333  0.337381  0.288571      0.37\n",
       "(SOC, ML Classical Features)                1  0.977778  0.983333  0.977778\n",
       "(SOC, Most Commonly Mentioned)        0.75125   0.75875  0.732286  0.784444\n",
       "(combined, First Mentioned)          0.128247  0.216959  0.153043  0.281681\n",
       "(combined, ML Classical Features)    0.909388  0.928898  0.915597  0.959832\n",
       "(combined, Most Commonly Mentioned)  0.785996  0.805625  0.788588  0.876471"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "program = {\n",
    "    (\"ASOIAF\", \"ML Classical Features\"):                (ann_ASOIAF, ML_mdl),\n",
    "    (\"SOC\", \"ML Classical Features\"):                   (ann_SOC, ML_mdl),\n",
    "    (\"combined\", \"ML Classical Features\"):              (ann_comb, ML_mdl),\n",
    "    \n",
    "    (\"SOC\", \"First Mentioned\"):                         (ann_SOC, FM_mdl),\n",
    "    (\"ASOIAF\", \"First Mentioned\"):                      (ann_ASOIAF, FM_mdl),\n",
    "    (\"combined\", \"First Mentioned\"):                    (ann_comb, FM_mdl),\n",
    "    \n",
    "    (\"SOC\", \"Most Commonly Mentioned\"):                 (ann_SOC, MC_mdl),\n",
    "    (\"ASOIAF\", \"Most Commonly Mentioned\"):              (ann_ASOIAF, MC_mdl),\n",
    "    (\"combined\", \"Most Commonly Mentioned\"):            (ann_comb, MC_mdl),\n",
    "}\n",
    "\n",
    "res_xval = pd.DataFrame(index=program.keys(), columns = all_metrics_names)\n",
    "res_xval.sort_index(inplace=True)\n",
    "\n",
    "for ind in res_xval.index:\n",
    "    print(ind, end=\"\")\n",
    "    score = xval_evaluate(*program[ind], metric=all_metrics) \n",
    "    res_xval.loc[ind, :] = score\n",
    "    print(\" \", score)\n",
    "    \n",
    "res_xval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save some trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(ann, filename):\n",
    "    mdl = MLCharacterSolver(XGBClassifier())\n",
    "    mdl.train(*extract_texts_and_characters(ann))\n",
    "    joblib.dump(mdl, \"../trained_models/\"+filename+\".pkl\")\n",
    "    return mdl\n",
    "\n",
    "train_and_save_model(ann_ASOIAF, \"classic_ASOIAF\")\n",
    "train_and_save_model(ann_SOC, \"classic_SOC\")\n",
    "\n",
    "mdl_comb = train_and_save_model(ann_comb, \"classic_comb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.07692308, 'occur_percent'),\n",
       " (0.07371795, 'last_occur_percent'),\n",
       " (0.057692308, 'rank'),\n",
       " (0.057692308, 'after_POS_was_VBD'),\n",
       " (0.051282052, 'rank_percent'),\n",
       " (0.049679488, 'before_POS_was_percent_.'),\n",
       " (0.043269232, 'last_occur_position'),\n",
       " (0.03846154, 'before_POS_was_percent_NN'),\n",
       " (0.033653848, 'before_POS_was_,')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_comb[1]['text'])\n",
    "feature_weights = list(zip(mdl_comb.classifier.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights[1:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([weight for weight, _ in feature_weights if weight>0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webstuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "book= load_book(\"../input_books/unlabelled/warbreaker/Warbreaker.epub\")\n",
    "texts, indexes = load_chapters(book)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([],\n",
       " array([], dtype=float64),\n",
       " ['occur_count',\n",
       "  'occur_percent',\n",
       "  'first_occur_position',\n",
       "  'first_occur_percent',\n",
       "  'last_occur_position',\n",
       "  'last_occur_percent',\n",
       "  'rank',\n",
       "  'rank_percent',\n",
       "  'before_POS_was_CC',\n",
       "  'after_POS_was_CC',\n",
       "  'before_POS_was_percent_CC',\n",
       "  'after_POS_was_percent_CC',\n",
       "  'before_POS_was_WP',\n",
       "  'after_POS_was_WP',\n",
       "  'before_POS_was_percent_WP',\n",
       "  'after_POS_was_percent_WP',\n",
       "  'before_POS_was_NNS',\n",
       "  'after_POS_was_NNS',\n",
       "  'before_POS_was_percent_NNS',\n",
       "  'after_POS_was_percent_NNS',\n",
       "  'before_POS_was_EX',\n",
       "  'after_POS_was_EX',\n",
       "  'before_POS_was_percent_EX',\n",
       "  'after_POS_was_percent_EX',\n",
       "  'before_POS_was_.',\n",
       "  'after_POS_was_.',\n",
       "  'before_POS_was_percent_.',\n",
       "  'after_POS_was_percent_.',\n",
       "  'before_POS_was_RP',\n",
       "  'after_POS_was_RP',\n",
       "  'before_POS_was_percent_RP',\n",
       "  'after_POS_was_percent_RP',\n",
       "  'before_POS_was_FW',\n",
       "  'after_POS_was_FW',\n",
       "  'before_POS_was_percent_FW',\n",
       "  'after_POS_was_percent_FW',\n",
       "  'before_POS_was_LS',\n",
       "  'after_POS_was_LS',\n",
       "  'before_POS_was_percent_LS',\n",
       "  'after_POS_was_percent_LS',\n",
       "  'before_POS_was_``',\n",
       "  'after_POS_was_``',\n",
       "  'before_POS_was_percent_``',\n",
       "  'after_POS_was_percent_``',\n",
       "  'before_POS_was_UH',\n",
       "  'after_POS_was_UH',\n",
       "  'before_POS_was_percent_UH',\n",
       "  'after_POS_was_percent_UH',\n",
       "  'before_POS_was_RBS',\n",
       "  'after_POS_was_RBS',\n",
       "  'before_POS_was_percent_RBS',\n",
       "  'after_POS_was_percent_RBS',\n",
       "  'before_POS_was_:',\n",
       "  'after_POS_was_:',\n",
       "  'before_POS_was_percent_:',\n",
       "  'after_POS_was_percent_:',\n",
       "  'before_POS_was_VBP',\n",
       "  'after_POS_was_VBP',\n",
       "  'before_POS_was_percent_VBP',\n",
       "  'after_POS_was_percent_VBP',\n",
       "  'before_POS_was_WRB',\n",
       "  'after_POS_was_WRB',\n",
       "  'before_POS_was_percent_WRB',\n",
       "  'after_POS_was_percent_WRB',\n",
       "  'before_POS_was_VBZ',\n",
       "  'after_POS_was_VBZ',\n",
       "  'before_POS_was_percent_VBZ',\n",
       "  'after_POS_was_percent_VBZ',\n",
       "  'before_POS_was_SYM',\n",
       "  'after_POS_was_SYM',\n",
       "  'before_POS_was_percent_SYM',\n",
       "  'after_POS_was_percent_SYM',\n",
       "  'before_POS_was_VBD',\n",
       "  'after_POS_was_VBD',\n",
       "  'before_POS_was_percent_VBD',\n",
       "  'after_POS_was_percent_VBD',\n",
       "  'before_POS_was_,',\n",
       "  'after_POS_was_,',\n",
       "  'before_POS_was_percent_,',\n",
       "  'after_POS_was_percent_,',\n",
       "  'before_POS_was_JJS',\n",
       "  'after_POS_was_JJS',\n",
       "  'before_POS_was_percent_JJS',\n",
       "  'after_POS_was_percent_JJS',\n",
       "  'before_POS_was_MD',\n",
       "  'after_POS_was_MD',\n",
       "  'before_POS_was_percent_MD',\n",
       "  'after_POS_was_percent_MD',\n",
       "  'before_POS_was_JJR',\n",
       "  'after_POS_was_JJR',\n",
       "  'before_POS_was_percent_JJR',\n",
       "  'after_POS_was_percent_JJR',\n",
       "  'before_POS_was_JJ',\n",
       "  'after_POS_was_JJ',\n",
       "  'before_POS_was_percent_JJ',\n",
       "  'after_POS_was_percent_JJ',\n",
       "  'before_POS_was_RBR',\n",
       "  'after_POS_was_RBR',\n",
       "  'before_POS_was_percent_RBR',\n",
       "  'after_POS_was_percent_RBR',\n",
       "  'before_POS_was_WDT',\n",
       "  'after_POS_was_WDT',\n",
       "  'before_POS_was_percent_WDT',\n",
       "  'after_POS_was_percent_WDT',\n",
       "  'before_POS_was_$',\n",
       "  'after_POS_was_$',\n",
       "  'before_POS_was_percent_$',\n",
       "  'after_POS_was_percent_$',\n",
       "  'before_POS_was_NNP',\n",
       "  'after_POS_was_NNP',\n",
       "  'before_POS_was_percent_NNP',\n",
       "  'after_POS_was_percent_NNP',\n",
       "  'before_POS_was_POS',\n",
       "  'after_POS_was_POS',\n",
       "  'before_POS_was_percent_POS',\n",
       "  'after_POS_was_percent_POS',\n",
       "  'before_POS_was_WP$',\n",
       "  'after_POS_was_WP$',\n",
       "  'before_POS_was_percent_WP$',\n",
       "  'after_POS_was_percent_WP$',\n",
       "  'before_POS_was_VBN',\n",
       "  'after_POS_was_VBN',\n",
       "  'before_POS_was_percent_VBN',\n",
       "  'after_POS_was_percent_VBN',\n",
       "  'before_POS_was_)',\n",
       "  'after_POS_was_)',\n",
       "  'before_POS_was_percent_)',\n",
       "  'after_POS_was_percent_)',\n",
       "  'before_POS_was_NNPS',\n",
       "  'after_POS_was_NNPS',\n",
       "  'before_POS_was_percent_NNPS',\n",
       "  'after_POS_was_percent_NNPS',\n",
       "  'before_POS_was_NN',\n",
       "  'after_POS_was_NN',\n",
       "  'before_POS_was_percent_NN',\n",
       "  'after_POS_was_percent_NN',\n",
       "  'before_POS_was_DT',\n",
       "  'after_POS_was_DT',\n",
       "  'before_POS_was_percent_DT',\n",
       "  'after_POS_was_percent_DT',\n",
       "  'before_POS_was_VBG',\n",
       "  'after_POS_was_VBG',\n",
       "  'before_POS_was_percent_VBG',\n",
       "  'after_POS_was_percent_VBG',\n",
       "  \"before_POS_was_''\",\n",
       "  \"after_POS_was_''\",\n",
       "  \"before_POS_was_percent_''\",\n",
       "  \"after_POS_was_percent_''\",\n",
       "  'before_POS_was_PDT',\n",
       "  'after_POS_was_PDT',\n",
       "  'before_POS_was_percent_PDT',\n",
       "  'after_POS_was_percent_PDT',\n",
       "  'before_POS_was_(',\n",
       "  'after_POS_was_(',\n",
       "  'before_POS_was_percent_(',\n",
       "  'after_POS_was_percent_(',\n",
       "  'before_POS_was_PRP',\n",
       "  'after_POS_was_PRP',\n",
       "  'before_POS_was_percent_PRP',\n",
       "  'after_POS_was_percent_PRP',\n",
       "  'before_POS_was_TO',\n",
       "  'after_POS_was_TO',\n",
       "  'before_POS_was_percent_TO',\n",
       "  'after_POS_was_percent_TO',\n",
       "  'before_POS_was_CD',\n",
       "  'after_POS_was_CD',\n",
       "  'before_POS_was_percent_CD',\n",
       "  'after_POS_was_percent_CD',\n",
       "  'before_POS_was_PRP$',\n",
       "  'after_POS_was_PRP$',\n",
       "  'before_POS_was_percent_PRP$',\n",
       "  'after_POS_was_percent_PRP$',\n",
       "  'before_POS_was_--',\n",
       "  'after_POS_was_--',\n",
       "  'before_POS_was_percent_--',\n",
       "  'after_POS_was_percent_--',\n",
       "  'before_POS_was_RB',\n",
       "  'after_POS_was_RB',\n",
       "  'before_POS_was_percent_RB',\n",
       "  'after_POS_was_percent_RB',\n",
       "  'before_POS_was_VB',\n",
       "  'after_POS_was_VB',\n",
       "  'before_POS_was_percent_VB',\n",
       "  'after_POS_was_percent_VB',\n",
       "  'before_POS_was_IN',\n",
       "  'after_POS_was_IN',\n",
       "  'before_POS_was_percent_IN',\n",
       "  'after_POS_was_percent_IN',\n",
       "  'before_POS_was_NE',\n",
       "  'after_POS_was_NE',\n",
       "  'before_POS_was_percent_NE',\n",
       "  'after_POS_was_percent_NE',\n",
       "  'before_POS_was_PAD',\n",
       "  'after_POS_was_PAD',\n",
       "  'before_POS_was_percent_PAD',\n",
       "  'after_POS_was_percent_PAD',\n",
       "  'before_POS_was_#',\n",
       "  'after_POS_was_#',\n",
       "  'before_POS_was_percent_#',\n",
       "  'after_POS_was_percent_#'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl_comb.feature_extractor(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input numpy.ndarray must be 2 dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-083225bea809>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmdl_comb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcharacter_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/public-html/apps/NovelPerspective/proto/classify.py\u001b[0m in \u001b[0;36mcharacter_scores\u001b[0;34m(self, raw_text)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcharacter_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_vectors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_vectors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#second index is positive class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, data, output_margin, ntree_limit)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mntree_limit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mtest_dmatrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m         class_probs = self.get_booster().predict(test_dmatrix,\n\u001b[1;32m    537\u001b[0m                                                  \u001b[0moutput_margin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_margin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, label, missing, weight, silent, feature_names, feature_types, nthread)\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 280\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_from_npy2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnthread\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.4/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36m_init_from_npy2d\u001b[0;34m(self, mat, missing, nthread)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \"\"\"\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input numpy.ndarray must be 2 dimensional'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m         \u001b[0;31m# flatten the array by rows and ensure it is float32.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;31m# we try to avoid data copies if possible (reshape returns a view when possible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input numpy.ndarray must be 2 dimensional"
     ]
    }
   ],
   "source": [
    "mdl_comb.character_scores(texts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
