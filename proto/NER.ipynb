{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "\n",
    "import json\n",
    "from xgboost import XGBClassifier\n",
    "import sklearn.tree\n",
    "import sklearn.metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sample_chapters import *\n",
    "from feature_extraction import *\n",
    "from classify import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_and_characters(annotated_data):\n",
    "    full_characters = np.asarray([datum['character'] for datum in annotated_data])\n",
    "    full_texts = np.asarray([datum['text'] for datum in annotated_data])\n",
    "    return full_texts, full_characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def evaluate(annotated_data, classifier=XGBClassifier(), nicknames2name=dict(), n_splits=10):\n",
    "    \n",
    "    full_texts, full_characters = extract_texts_and_characters(annotated_data)\n",
    "    \n",
    "    scores = []\n",
    "    for train_inds, test_inds in KFold(n_splits=n_splits).split(annotated_data):\n",
    "        train_texts = full_texts[train_inds]\n",
    "        train_characters = full_characters[train_inds]\n",
    "        \n",
    "        test_characters = full_characters[test_inds]\n",
    "        test_texts = full_texts[test_inds]\n",
    "        \n",
    "\n",
    "        train_classifier(train_texts, train_characters, classifier)\n",
    "        score = test_classifier(test_texts, test_characters, classifier, nicknames2name)\n",
    "        \n",
    "        print(score)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nicknames2name_comb = {\n",
    "    \"Dany\":\"Daenerys\",\n",
    "    \"Ned\" : \"Eddard\",\n",
    "    \"Sam\" : \"Samwell\",\n",
    "    \"Rollins\" : \"Pekka\"\n",
    "}\n",
    "  \n",
    "with open(\"../flat_data/asoif01-04.json\",\"r\") as fh:\n",
    "    ann_GoT = np.asarray(json.load(fh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9230769230769231\n",
      "0.8846153846153846\n",
      "0.9615384615384616\n",
      "1.0\n",
      "0.9230769230769231\n"
     ]
    }
   ],
   "source": [
    "scores = evaluate(ann_GoT, XGBClassifier(), nicknames2name_comb)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_Dregs = np.asarray(json.load(fh))\n",
    "with open(\"../flat_data/dregs01.json\",\"r\") as fh:\n",
    "    ann_Dregs = np.hstack([ann_Dregs, np.asarray(json.load(fh))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_comb = np.hstack([ann_GoT, ann_Dregs])\n",
    "np.random.shuffle(ann_comb)\n",
    "                     \n",
    "scores = evaluate(ann_comb,\n",
    "                  XGBClassifier(), nicknames2name_GoT)\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_characters = list(run_classifier(extract_texts_and_characters(ann_Dregs)[0], \n",
    "                       classifier=cls))\n",
    "reference_characters = extract_texts_and_characters(ann_Dregs)[1]\n",
    "print(\"acc: \", sklearn.metrics.accuracy_score(output_characters, reference_characters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = train_classifier(*extract_texts_and_characters(ann_GoT), \n",
    "                       classifier=XGBClassifier())\n",
    "\n",
    "output_characters = list(run_classifier(extract_texts_and_characters(ann_GoT)[0], \n",
    "                       classifier=cls,\n",
    "                       nicknames2name=nicknames2name_GoT))\n",
    "reference_characters = [datum['character'] for datum in ann_GoT]\n",
    "\n",
    "print(\"acc: \", sklearn.metrics.accuracy_score(output_characters, reference_characters))\n",
    "\n",
    "joblib.dump(cls, \"../trained_models/GoT-no-headings.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature importance stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "_, _,vector_keys = get_feature_vectors(ann_GoT[1]['text'])\n",
    "feature_weights = list(zip(cls.feature_importances_,vector_keys))\n",
    "feature_weights.sort(reverse=True)\n",
    "feature_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = evaluate(ann_GoT, nicknames2name_GoT, XGBClassifier(n_estimators=100))\n",
    "np.mean(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../flat_data/Warbreaker.json\",\"r\") as fh:\n",
    "    warbreaker = json.load(fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls = joblib.load(\"trained_models/GoT-no-headings.pkl\")\n",
    "warbreaker_characters = run_classifier(extract_texts_and_characters(warbreaker)[0], \n",
    "                       classifier=cls,)\n",
    "ann_warbreaker = [(char, datum['text'][1:125]) for char,datum in zip(warbreaker_characters, warbreaker)]\n",
    "ann_warbreaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for imp, name in zip(classifier.feature_importances_, FeatureVec().keys()):\n",
    "    print(name, \"\\t\", imp )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
